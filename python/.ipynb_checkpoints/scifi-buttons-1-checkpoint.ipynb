{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmu/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 2e6 # Set maximum number of steps to run environment.\n",
    "run_path = \"scifibuttons4\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 5000 # Frequency at which to save training statistics.\n",
    "save_freq = 20000 # Frequency at which to save model.\n",
    "env_name = \"scifibuttons4\" # Name of the training environment file.\n",
    "curriculum_file = 'curricula/lessons.json'\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 1e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 2 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 5000 #2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 128 # Number of units in hidden layer.\n",
    "batch_size = 64 #64 # How many experiences per gradient descent update step.\n",
    "normalize = False\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\tlessonNr -> 1.0\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 16\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 4\n",
      "        Memory space size (per agent): 3\n",
      "        Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Mean Reward: 0.29113695652173915. Std of Reward: 0.9836648329320609.\n",
      "Step: 10000. Mean Reward: 0.2097938524590164. Std of Reward: 1.0093367369355886.\n",
      "Step: 15000. Mean Reward: 0.11098235294117649. Std of Reward: 1.032451091653695.\n",
      "Step: 20000. Mean Reward: 0.33194377510040163. Std of Reward: 0.9813454112575196.\n",
      "Saved Model\n",
      "Step: 25000. Mean Reward: 0.3011701960784313. Std of Reward: 0.9891288344751444.\n",
      "Step: 30000. Mean Reward: 0.3405857142857143. Std of Reward: 0.9824342856920529.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 1 : \tlessonNr -> 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 35000. Mean Reward: 0.34730326086956526. Std of Reward: 0.9517953764970971.\n",
      "Step: 40000. Mean Reward: 0.21278410852713184. Std of Reward: 0.9850780107321863.\n",
      "Saved Model\n",
      "Step: 45000. Mean Reward: 0.08454101382488485. Std of Reward: 1.025914169083887.\n",
      "Step: 50000. Mean Reward: 0.3437902621722847. Std of Reward: 0.9471419228012486.\n",
      "Step: 55000. Mean Reward: 0.22445209790209794. Std of Reward: 0.9802726472696814.\n",
      "Step: 60000. Mean Reward: 0.27222. Std of Reward: 0.9736648864984297.\n",
      "Saved Model\n",
      "Step: 65000. Mean Reward: 0.20386321839080462. Std of Reward: 0.9785518469611993.\n",
      "Step: 70000. Mean Reward: 0.2269149425287357. Std of Reward: 0.9748564002547847.\n",
      "Step: 75000. Mean Reward: 0.19175513698630142. Std of Reward: 0.9850752778450774.\n",
      "Step: 80000. Mean Reward: 0.157643893129771. Std of Reward: 1.000293382736623.\n",
      "Saved Model\n",
      "Step: 85000. Mean Reward: 0.3242755172413793. Std of Reward: 0.9461264701788068.\n",
      "Step: 90000. Mean Reward: 0.19285617977528094. Std of Reward: 0.9953342190216528.\n",
      "Step: 95000. Mean Reward: 0.2601507352941177. Std of Reward: 0.9650113993913967.\n",
      "Step: 100000. Mean Reward: 0.28731570512820515. Std of Reward: 0.9603715023248597.\n",
      "Saved Model\n",
      "Step: 105000. Mean Reward: 0.3058390845070423. Std of Reward: 0.9555240874761082.\n",
      "Step: 110000. Mean Reward: 0.32524437299035375. Std of Reward: 0.9348902621566932.\n",
      "Step: 115000. Mean Reward: 0.20659807692307694. Std of Reward: 0.9851534639705758.\n",
      "Step: 120000. Mean Reward: 0.401439263803681. Std of Reward: 0.9072904159572068.\n",
      "Saved Model\n",
      "Step: 125000. Mean Reward: 0.3733025078369906. Std of Reward: 0.9153450258206743.\n",
      "Step: 130000. Mean Reward: 0.3010028571428571. Std of Reward: 0.9571299533682424.\n",
      "Step: 135000. Mean Reward: 0.2608632996632997. Std of Reward: 0.9664828509489125.\n",
      "Step: 140000. Mean Reward: 0.37713968253968255. Std of Reward: 0.9136105107983211.\n",
      "Saved Model\n",
      "Step: 145000. Mean Reward: 0.38144730158730167. Std of Reward: 0.9181176597579339.\n",
      "Step: 150000. Mean Reward: 0.2875309090909091. Std of Reward: 0.9714976641852286.\n",
      "Step: 155000. Mean Reward: 0.4769421602787457. Std of Reward: 0.8668687777106459.\n",
      "Step: 160000. Mean Reward: 0.37198283828382844. Std of Reward: 0.9192339936517868.\n",
      "Saved Model\n",
      "Step: 165000. Mean Reward: 0.3999098039215686. Std of Reward: 0.917575004557584.\n",
      "Step: 170000. Mean Reward: 0.3519196013289037. Std of Reward: 0.9321763536300149.\n",
      "Step: 175000. Mean Reward: 0.2993264026402641. Std of Reward: 0.9381597459248919.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 2 : \tlessonNr -> 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 180000. Mean Reward: -0.064517619047619. Std of Reward: 0.9952141898793386.\n",
      "Saved Model\n",
      "Step: 185000. Mean Reward: -0.24363622448979586. Std of Reward: 0.9725551132612709.\n",
      "Step: 190000. Mean Reward: -0.15616061452513963. Std of Reward: 0.9903175231656804.\n",
      "Step: 195000. Mean Reward: -0.14737486631016042. Std of Reward: 0.9950658044557529.\n",
      "Step: 200000. Mean Reward: -0.15020243902439023. Std of Reward: 0.9915039667690252.\n",
      "Saved Model\n",
      "Step: 205000. Mean Reward: -0.1779914600550964. Std of Reward: 0.9928219031425407.\n",
      "Step: 210000. Mean Reward: -0.07860855457227137. Std of Reward: 1.0083076011810017.\n",
      "Step: 215000. Mean Reward: 0.13887671232876717. Std of Reward: 0.9811867495881064.\n",
      "Step: 220000. Mean Reward: 0.059563600000000036. Std of Reward: 1.0034423195356272.\n",
      "Saved Model\n",
      "Step: 225000. Mean Reward: 0.13919579288025893. Std of Reward: 1.0119285197144243.\n",
      "Step: 230000. Mean Reward: 0.044967638483965046. Std of Reward: 1.0022723575698627.\n",
      "Step: 235000. Mean Reward: 0.05889218750000004. Std of Reward: 1.0142250454942014.\n",
      "Step: 240000. Mean Reward: 0.14790716612377855. Std of Reward: 1.01666725877381.\n",
      "Saved Model\n",
      "Step: 245000. Mean Reward: 0.10954864864864867. Std of Reward: 1.0178227741902497.\n",
      "Step: 250000. Mean Reward: 0.24041918238993715. Std of Reward: 0.96739513704221.\n",
      "Step: 255000. Mean Reward: 0.16191972318339104. Std of Reward: 0.9886413866916094.\n",
      "Step: 260000. Mean Reward: 0.3573067961165049. Std of Reward: 0.9238452337073458.\n",
      "Saved Model\n",
      "Step: 265000. Mean Reward: 0.29578555956678704. Std of Reward: 0.969991086940773.\n",
      "Step: 270000. Mean Reward: 0.3579027972027973. Std of Reward: 0.943171251196242.\n",
      "Step: 275000. Mean Reward: 0.43274592833876224. Std of Reward: 0.8952015435592777.\n",
      "Step: 280000. Mean Reward: 0.3865143344709898. Std of Reward: 0.9251069838322145.\n",
      "Saved Model\n",
      "Step: 285000. Mean Reward: 0.3795603278688525. Std of Reward: 0.9280287522926537.\n",
      "Step: 290000. Mean Reward: 0.2960172566371679. Std of Reward: 1.0384971448371707.\n",
      "Step: 295000. Mean Reward: 0.3570463503649635. Std of Reward: 0.9432008827325227.\n",
      "Step: 300000. Mean Reward: 0.304845581395348. Std of Reward: 1.1444185616901508.\n",
      "Saved Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 3 : \tlessonNr -> 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 305000. Mean Reward: 0.501560409556314. Std of Reward: 0.8504078469852961.\n",
      "Step: 310000. Mean Reward: -0.6842840000000052. Std of Reward: 1.9287105096784407.\n",
      "Step: 315000. Mean Reward: -0.3780948979591841. Std of Reward: 1.2981792467169657.\n",
      "Step: 320000. Mean Reward: -0.6024318181818185. Std of Reward: 1.475171044233577.\n",
      "Saved Model\n",
      "Step: 325000. Mean Reward: -0.3283454545454601. Std of Reward: 1.910295389611337.\n",
      "Step: 330000. Mean Reward: -0.5538169014084525. Std of Reward: 1.4954082339592916.\n",
      "Step: 335000. Mean Reward: -0.6043620689655207. Std of Reward: 1.8018614142456941.\n",
      "Step: 340000. Mean Reward: -0.6772111111111199. Std of Reward: 2.000339673069163.\n",
      "Saved Model\n",
      "Step: 345000. Mean Reward: -0.6973000000000024. Std of Reward: 1.6307938954612637.\n",
      "Step: 350000. Mean Reward: -0.4992409836065611. Std of Reward: 1.8199300594899646.\n",
      "Step: 355000. Mean Reward: -0.3550824324324346. Std of Reward: 1.5261969284535826.\n",
      "Step: 360000. Mean Reward: -0.6097307692307743. Std of Reward: 2.1072037286540013.\n",
      "Saved Model\n",
      "Step: 365000. Mean Reward: -0.5478224137931119. Std of Reward: 2.1013507758388257.\n",
      "Step: 370000. Mean Reward: -0.256917910447762. Std of Reward: 1.3950867954515966.\n",
      "Step: 375000. Mean Reward: -0.9601255813953603. Std of Reward: 2.5513452203752838.\n",
      "Step: 380000. Mean Reward: -0.2937595238095255. Std of Reward: 1.4973378528256593.\n",
      "Saved Model\n",
      "Step: 385000. Mean Reward: -0.3760082191780862. Std of Reward: 1.694265006826605.\n",
      "Step: 390000. Mean Reward: -0.33769449541284435. Std of Reward: 1.173645877294682.\n",
      "Step: 395000. Mean Reward: -0.3829833333333362. Std of Reward: 1.562263503755596.\n",
      "Step: 400000. Mean Reward: -0.2605831578947368. Std of Reward: 1.0940976175684576.\n",
      "Saved Model\n",
      "Step: 405000. Mean Reward: -0.20307522935779806. Std of Reward: 1.197917715707802.\n",
      "Step: 410000. Mean Reward: -0.5817862745098096. Std of Reward: 1.935264504596944.\n",
      "Step: 415000. Mean Reward: -0.543623333333336. Std of Reward: 1.6624336077336332.\n",
      "Step: 420000. Mean Reward: -0.208323437500002. Std of Reward: 1.8167648316910667.\n",
      "Saved Model\n",
      "Step: 425000. Mean Reward: -0.024970652173914615. Std of Reward: 1.4005045996337373.\n",
      "Step: 430000. Mean Reward: -0.013639024390246795. Std of Reward: 1.5528959786245697.\n",
      "Step: 435000. Mean Reward: -0.22970517241379432. Std of Reward: 1.4982940341949886.\n",
      "Step: 440000. Mean Reward: -0.30957974683544703. Std of Reward: 1.6413496865427317.\n",
      "Saved Model\n",
      "Step: 445000. Mean Reward: 0.006385526315786823. Std of Reward: 1.6935443141921809.\n",
      "Step: 450000. Mean Reward: -0.1741366666666666. Std of Reward: 1.2551845793835352.\n",
      "Step: 455000. Mean Reward: 0.01682500000000005. Std of Reward: 1.104755010549096.\n",
      "Step: 460000. Mean Reward: -0.10177708333333328. Std of Reward: 1.0563994814817104.\n",
      "Saved Model\n",
      "Step: 465000. Mean Reward: -0.6655054054054129. Std of Reward: 2.278671430241296.\n",
      "Step: 470000. Mean Reward: -0.22329411764706356. Std of Reward: 1.6733545426058356.\n",
      "Step: 475000. Mean Reward: -0.06794594594594772. Std of Reward: 1.5934168104023458.\n",
      "Step: 480000. Mean Reward: 0.10452222222222037. Std of Reward: 1.3945545816000735.\n",
      "Saved Model\n",
      "Step: 485000. Mean Reward: 0.07400990099009876. Std of Reward: 1.1869466574470589.\n",
      "Step: 490000. Mean Reward: 0.2036155339805826. Std of Reward: 1.063268233175912.\n",
      "Step: 495000. Mean Reward: 0.06325151515151493. Std of Reward: 1.1471928434546066.\n",
      "Step: 500000. Mean Reward: -0.003592929292931111. Std of Reward: 1.3155644938294648.\n",
      "Saved Model\n",
      "Step: 505000. Mean Reward: 0.178513559322034. Std of Reward: 0.9661637094949067.\n",
      "Step: 510000. Mean Reward: -0.010071428571430407. Std of Reward: 1.5976414446091822.\n",
      "Step: 515000. Mean Reward: 0.2860327102803739. Std of Reward: 0.9758593324760003.\n",
      "Step: 520000. Mean Reward: -0.038164044943822875. Std of Reward: 1.6730752040054384.\n",
      "Saved Model\n",
      "Step: 525000. Mean Reward: 0.08026391752577326. Std of Reward: 1.0813520332584.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 4 : \tlessonNr -> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 530000. Mean Reward: -0.5372950000000051. Std of Reward: 1.9191579203238462.\n",
      "Step: 535000. Mean Reward: -0.5609809523809546. Std of Reward: 1.2682275188771182.\n",
      "Step: 540000. Mean Reward: -0.45715454545454554. Std of Reward: 1.174228728193832.\n",
      "Saved Model\n",
      "Step: 545000. Mean Reward: -0.8282171875000024. Std of Reward: 1.3400435935720043.\n",
      "Step: 550000. Mean Reward: -0.48732222222222216. Std of Reward: 0.9710052076757021.\n",
      "Step: 555000. Mean Reward: -0.7058907407407415. Std of Reward: 1.143720055308235.\n",
      "Step: 560000. Mean Reward: -0.43197833333333396. Std of Reward: 1.2028409306154717.\n",
      "Saved Model\n",
      "Step: 565000. Mean Reward: -0.5846983333333335. Std of Reward: 1.0432192833550813.\n",
      "Step: 570000. Mean Reward: -0.9062117647058857. Std of Reward: 1.597887964323004.\n",
      "Step: 575000. Mean Reward: -0.53521525423729. Std of Reward: 1.4203617705566627.\n",
      "Step: 580000. Mean Reward: -0.7054112903225807. Std of Reward: 1.0454284940457914.\n",
      "Saved Model\n",
      "Step: 585000. Mean Reward: -0.851603846153847. Std of Reward: 1.1895775433000044.\n",
      "Step: 590000. Mean Reward: -0.7098426229508223. Std of Reward: 1.6022490821136839.\n",
      "Step: 595000. Mean Reward: -0.5101016129032264. Std of Reward: 1.1125984519672782.\n",
      "Step: 600000. Mean Reward: -0.8895577777777824. Std of Reward: 1.6071051792294846.\n",
      "Saved Model\n",
      "Step: 605000. Mean Reward: -0.9022658536585383. Std of Reward: 1.4006372728346028.\n",
      "Step: 610000. Mean Reward: -0.7938163934426254. Std of Reward: 1.429743358052496.\n",
      "Step: 615000. Mean Reward: -0.8688810344827602. Std of Reward: 1.206822185636217.\n",
      "Step: 620000. Mean Reward: -1.0451743589743674. Std of Reward: 2.152135671387984.\n",
      "Saved Model\n",
      "Step: 625000. Mean Reward: -0.8277326530612246. Std of Reward: 0.9442273842774801.\n",
      "Step: 630000. Mean Reward: -0.6068962962962992. Std of Reward: 1.3922516028153356.\n",
      "Step: 635000. Mean Reward: -1.6552347826087108. Std of Reward: 2.489422794040018.\n",
      "Step: 640000. Mean Reward: -0.6045849999999999. Std of Reward: 1.1738558163626118.\n",
      "Saved Model\n",
      "Step: 645000. Mean Reward: -1.0711145833333362. Std of Reward: 1.3938458200230344.\n",
      "Step: 650000. Mean Reward: -0.5638092307692307. Std of Reward: 0.9873252359041851.\n",
      "Step: 655000. Mean Reward: -0.42614374999999993. Std of Reward: 1.0183175767649488.\n",
      "Step: 660000. Mean Reward: -1.155353125000006. Std of Reward: 1.758565867579404.\n",
      "Saved Model\n",
      "Step: 665000. Mean Reward: -0.6936200000000018. Std of Reward: 1.2881416114698014.\n",
      "Step: 670000. Mean Reward: -0.7666659999999998. Std of Reward: 1.0537766210369255.\n",
      "Step: 675000. Mean Reward: -0.6224150943396227. Std of Reward: 0.9680288289789859.\n",
      "Step: 680000. Mean Reward: -0.6199833333333344. Std of Reward: 1.140732510353228.\n",
      "Saved Model\n",
      "Step: 685000. Mean Reward: -0.7911354166666675. Std of Reward: 1.358953273891588.\n",
      "Step: 690000. Mean Reward: -1.0240142857142902. Std of Reward: 1.6299258344214145.\n",
      "Step: 695000. Mean Reward: -0.6035566666666689. Std of Reward: 1.3938029313556437.\n",
      "Step: 700000. Mean Reward: -1.008835483870975. Std of Reward: 1.8795664013617812.\n",
      "Saved Model\n",
      "Step: 705000. Mean Reward: -0.5554596491228088. Std of Reward: 1.2446887864195164.\n",
      "Step: 710000. Mean Reward: -0.46536. Std of Reward: 1.2278297050299147.\n",
      "Step: 715000. Mean Reward: -0.5739194029850747. Std of Reward: 1.0413914591142284.\n",
      "Step: 720000. Mean Reward: -0.6548080645161323. Std of Reward: 1.3139072076896723.\n",
      "Saved Model\n",
      "Step: 725000. Mean Reward: -0.580740816326531. Std of Reward: 1.2651800412199745.\n",
      "Step: 730000. Mean Reward: -0.5431961538461538. Std of Reward: 1.3044934528186587.\n",
      "Step: 735000. Mean Reward: -0.8257129032258079. Std of Reward: 1.4854146458669704.\n",
      "Step: 740000. Mean Reward: -0.7081458333333334. Std of Reward: 1.3782163873642288.\n",
      "Saved Model\n",
      "Step: 745000. Mean Reward: -0.5022800000000017. Std of Reward: 1.5348403871195742.\n",
      "Step: 750000. Mean Reward: -0.7559256410256467. Std of Reward: 2.0984134934752574.\n",
      "Step: 755000. Mean Reward: -0.5809702127659597. Std of Reward: 1.32713974763438.\n",
      "Step: 760000. Mean Reward: -0.7107500000000047. Std of Reward: 1.6621071152305624.\n",
      "Saved Model\n",
      "Step: 765000. Mean Reward: -0.6186704545454549. Std of Reward: 1.2203662614484283.\n",
      "Step: 770000. Mean Reward: -1.210600000000007. Std of Reward: 1.906571751379418.\n",
      "Step: 775000. Mean Reward: -0.9053052631578985. Std of Reward: 1.7200278951145955.\n",
      "Step: 780000. Mean Reward: -1.2030062500000094. Std of Reward: 2.0761188390145313.\n",
      "Saved Model\n",
      "Step: 785000. Mean Reward: -0.3398017857142857. Std of Reward: 0.9824876117886884.\n",
      "Step: 790000. Mean Reward: -0.6582517857142864. Std of Reward: 1.2384518753253264.\n",
      "Step: 795000. Mean Reward: -0.6957600000000013. Std of Reward: 1.2325146292032436.\n",
      "Step: 800000. Mean Reward: -0.6427095238095245. Std of Reward: 1.1186044300205868.\n",
      "Saved Model\n",
      "Step: 805000. Mean Reward: -0.7346888888888925. Std of Reward: 1.5071542202991255.\n",
      "Step: 810000. Mean Reward: -0.5065686274509806. Std of Reward: 1.2141799355443619.\n",
      "Step: 815000. Mean Reward: -0.7006596153846177. Std of Reward: 1.3328627004222136.\n",
      "Step: 820000. Mean Reward: -0.5181818181818194. Std of Reward: 1.2991624562268702.\n",
      "Saved Model\n",
      "Step: 825000. Mean Reward: -0.5872365384615386. Std of Reward: 1.1561682574895753.\n",
      "Step: 830000. Mean Reward: -0.49421206896551856. Std of Reward: 1.2241147155897274.\n",
      "Step: 835000. Mean Reward: -0.7393210526315834. Std of Reward: 1.7813188554607489.\n",
      "Step: 840000. Mean Reward: -0.6359052631578992. Std of Reward: 1.69760507991134.\n",
      "Saved Model\n",
      "Step: 845000. Mean Reward: -0.5009214285714285. Std of Reward: 1.2535036948937346.\n",
      "Step: 850000. Mean Reward: -0.3620354838709681. Std of Reward: 1.0372248375254072.\n",
      "Step: 855000. Mean Reward: -0.44926617647058825. Std of Reward: 0.9929965088811172.\n",
      "Step: 860000. Mean Reward: -0.652455263157898. Std of Reward: 1.555116256053145.\n",
      "Saved Model\n",
      "Step: 865000. Mean Reward: -0.6986531914893631. Std of Reward: 1.1846436539082732.\n",
      "Step: 870000. Mean Reward: -0.754936. Std of Reward: 1.207967079147441.\n",
      "Step: 875000. Mean Reward: -0.20406842105263154. Std of Reward: 1.1635507709363737.\n",
      "Step: 880000. Mean Reward: -0.5243744680851068. Std of Reward: 0.9990029083228361.\n",
      "Saved Model\n",
      "Step: 885000. Mean Reward: -0.43204509803921565. Std of Reward: 1.016605456912853.\n",
      "Step: 890000. Mean Reward: -0.3295627450980423. Std of Reward: 1.4864514679771155.\n",
      "Step: 895000. Mean Reward: -0.38620612244898395. Std of Reward: 1.6742688397989616.\n",
      "Step: 900000. Mean Reward: -0.8326722222222253. Std of Reward: 1.6218068472490763.\n",
      "Saved Model\n",
      "Step: 905000. Mean Reward: -0.3623724137931035. Std of Reward: 1.0472521821567644.\n",
      "Step: 910000. Mean Reward: -0.5814076923076951. Std of Reward: 1.4448465457307584.\n",
      "Step: 915000. Mean Reward: -0.5107666666666673. Std of Reward: 1.3496387236121787.\n",
      "Step: 920000. Mean Reward: -0.558152830188681. Std of Reward: 1.2782363335388345.\n",
      "Saved Model\n",
      "Step: 925000. Mean Reward: -0.41627804878048924. Std of Reward: 1.239917989914366.\n",
      "Step: 930000. Mean Reward: -0.3400870370370393. Std of Reward: 1.643237630416608.\n",
      "Step: 935000. Mean Reward: -0.3862377777777808. Std of Reward: 1.5965045904223256.\n",
      "Step: 940000. Mean Reward: -0.3752769230769251. Std of Reward: 1.2107754210573929.\n",
      "Saved Model\n",
      "Step: 945000. Mean Reward: -0.5652520833333357. Std of Reward: 1.2932692080843093.\n",
      "Step: 950000. Mean Reward: -0.5178439024390246. Std of Reward: 1.1055482513763737.\n",
      "Step: 955000. Mean Reward: -0.319857894736842. Std of Reward: 1.020403577357159.\n",
      "Step: 960000. Mean Reward: -0.2240588235294117. Std of Reward: 0.9954666130595556.\n",
      "Saved Model\n",
      "Step: 965000. Mean Reward: -0.4144818181818181. Std of Reward: 0.9345410480971461.\n",
      "Step: 970000. Mean Reward: -0.42919333333333604. Std of Reward: 1.3524479472259152.\n",
      "Step: 975000. Mean Reward: -0.6317200000000023. Std of Reward: 1.5771614499156468.\n",
      "Step: 980000. Mean Reward: -0.5671326530612245. Std of Reward: 1.2207205987277627.\n",
      "Saved Model\n",
      "Step: 985000. Mean Reward: -0.46420600000000023. Std of Reward: 1.19728165665561.\n",
      "Step: 990000. Mean Reward: -0.45624999999999993. Std of Reward: 1.0571226194250127.\n",
      "Step: 995000. Mean Reward: -0.33798974358974354. Std of Reward: 1.0023426272781721.\n",
      "Step: 1000000. Mean Reward: -0.49604782608695647. Std of Reward: 1.0679766574022784.\n",
      "Saved Model\n",
      "Step: 1005000. Mean Reward: -0.4626461538461537. Std of Reward: 1.0392218359947427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1010000. Mean Reward: -0.4482775510204081. Std of Reward: 1.0220176954946558.\n",
      "Step: 1015000. Mean Reward: -0.8625666666666689. Std of Reward: 1.6103741402087322.\n",
      "Step: 1020000. Mean Reward: -0.15257727272727264. Std of Reward: 0.959369786164169.\n",
      "Saved Model\n",
      "Step: 1025000. Mean Reward: -0.09124791666666661. Std of Reward: 1.0739352583663162.\n",
      "Step: 1030000. Mean Reward: -0.6975388888888939. Std of Reward: 1.6743005848675194.\n",
      "Step: 1035000. Mean Reward: -0.33158750000000087. Std of Reward: 1.2100487288096118.\n",
      "Step: 1040000. Mean Reward: -0.32575744680851226. Std of Reward: 1.264219650445374.\n",
      "Saved Model\n",
      "Step: 1045000. Mean Reward: -0.9578294117647064. Std of Reward: 1.1747861731669997.\n",
      "Step: 1050000. Mean Reward: -0.2557174603174603. Std of Reward: 0.9120879100870065.\n",
      "Step: 1055000. Mean Reward: -0.5644372093023261. Std of Reward: 1.203524264549601.\n",
      "Step: 1060000. Mean Reward: -0.5134163265306148. Std of Reward: 1.6011915099606995.\n",
      "Saved Model\n",
      "Step: 1065000. Mean Reward: -0.5408974999999999. Std of Reward: 1.066991839586297.\n",
      "Step: 1070000. Mean Reward: -0.22305423728813553. Std of Reward: 0.9665779674851936.\n",
      "Step: 1075000. Mean Reward: -0.46325555555555553. Std of Reward: 1.0232261348424854.\n",
      "Step: 1080000. Mean Reward: -0.349976. Std of Reward: 1.062150815950353.\n",
      "Saved Model\n",
      "Step: 1085000. Mean Reward: -0.33915208333333613. Std of Reward: 1.3285978743255464.\n",
      "Step: 1090000. Mean Reward: -0.2951624999999999. Std of Reward: 1.0107556724271944.\n",
      "Step: 1095000. Mean Reward: -0.21642586206896544. Std of Reward: 1.0934420515936005.\n",
      "Step: 1100000. Mean Reward: -0.4337074074074073. Std of Reward: 0.9528957810667229.\n",
      "Saved Model\n",
      "Step: 1105000. Mean Reward: -0.4707638888888888. Std of Reward: 1.3275891405837832.\n",
      "Step: 1110000. Mean Reward: -0.8562771428571505. Std of Reward: 2.209759470050453.\n",
      "Step: 1115000. Mean Reward: -0.4518132075471697. Std of Reward: 1.0368254180725942.\n",
      "Step: 1120000. Mean Reward: -0.6170333333333382. Std of Reward: 1.6502772412511522.\n",
      "Saved Model\n",
      "Step: 1125000. Mean Reward: -0.3267186440677965. Std of Reward: 1.1000604446373792.\n",
      "Step: 1130000. Mean Reward: -0.28702500000000264. Std of Reward: 1.381258762541347.\n",
      "Step: 1135000. Mean Reward: -0.40869302325581597. Std of Reward: 1.4652679363516392.\n",
      "Step: 1140000. Mean Reward: 0.08556818181818183. Std of Reward: 0.9448799858309874.\n",
      "Saved Model\n",
      "Step: 1145000. Mean Reward: -0.6751972222222276. Std of Reward: 1.743192295041585.\n",
      "Step: 1150000. Mean Reward: -0.1688760563380282. Std of Reward: 1.0913794171797464.\n",
      "Step: 1155000. Mean Reward: -0.424302380952381. Std of Reward: 1.1630116071336798.\n",
      "Step: 1160000. Mean Reward: -0.3383677966101694. Std of Reward: 1.0851680985834777.\n",
      "Saved Model\n",
      "Step: 1165000. Mean Reward: -0.18601799999999993. Std of Reward: 1.0427420951874917.\n",
      "Step: 1170000. Mean Reward: -0.262009090909091. Std of Reward: 1.1327918618800183.\n",
      "Step: 1175000. Mean Reward: -0.5706000000000004. Std of Reward: 1.3966697818544866.\n",
      "Step: 1180000. Mean Reward: 0.007831666666666761. Std of Reward: 0.9790984510408315.\n",
      "Saved Model\n",
      "Step: 1185000. Mean Reward: -0.7270690476190528. Std of Reward: 1.7152264585301908.\n",
      "Step: 1190000. Mean Reward: -0.30435833333333323. Std of Reward: 0.9722035085381501.\n",
      "Step: 1195000. Mean Reward: 0.13111132075471704. Std of Reward: 0.847250580353638.\n",
      "Step: 1200000. Mean Reward: -0.23379636363636358. Std of Reward: 1.0067062901026453.\n",
      "Saved Model\n",
      "Step: 1205000. Mean Reward: 0.0333720000000001. Std of Reward: 0.9016863973777136.\n",
      "Step: 1210000. Mean Reward: -0.17069999999999996. Std of Reward: 1.056903374522441.\n",
      "Step: 1215000. Mean Reward: -0.00691097560975602. Std of Reward: 0.9116666684659098.\n",
      "Step: 1220000. Mean Reward: -0.17603709677419346. Std of Reward: 0.9472027212992646.\n",
      "Saved Model\n",
      "Step: 1225000. Mean Reward: -0.44900000000000684. Std of Reward: 1.9105597363479503.\n",
      "Step: 1230000. Mean Reward: -0.12044782608695787. Std of Reward: 1.3497638419431104.\n",
      "Step: 1235000. Mean Reward: -0.1997687499999999. Std of Reward: 0.974491306540719.\n",
      "Step: 1240000. Mean Reward: -0.4615500000000033. Std of Reward: 1.721818834546787.\n",
      "Saved Model\n",
      "Step: 1245000. Mean Reward: 0.043406779661017046. Std of Reward: 0.9196312890232946.\n",
      "Step: 1250000. Mean Reward: -0.3558083333333333. Std of Reward: 1.2121259302415277.\n",
      "Step: 1255000. Mean Reward: -0.2285685185185215. Std of Reward: 1.3837163626108893.\n",
      "Step: 1260000. Mean Reward: -0.25637441860465104. Std of Reward: 1.1053242165827168.\n",
      "Saved Model\n",
      "Step: 1265000. Mean Reward: -0.7080200000000036. Std of Reward: 1.6768140299985688.\n",
      "Step: 1270000. Mean Reward: -0.5806435897435941. Std of Reward: 1.639743871618448.\n",
      "Step: 1275000. Mean Reward: -0.03262075471698108. Std of Reward: 0.9570028381414295.\n",
      "Step: 1280000. Mean Reward: -0.13927222222222418. Std of Reward: 1.395660623400223.\n",
      "Saved Model\n",
      "Step: 1285000. Mean Reward: -0.4387047619047619. Std of Reward: 1.040397770761691.\n",
      "Step: 1290000. Mean Reward: -0.2512723404255318. Std of Reward: 1.1720568960305726.\n",
      "Step: 1295000. Mean Reward: -0.2263961538461547. Std of Reward: 1.292462032616218.\n",
      "Step: 1300000. Mean Reward: -0.45070000000000143. Std of Reward: 1.399599600906331.\n",
      "Saved Model\n",
      "Step: 1305000. Mean Reward: -0.3539588235294165. Std of Reward: 1.7646495051288835.\n",
      "Step: 1310000. Mean Reward: -0.23903333333333446. Std of Reward: 1.4349023410439274.\n",
      "Step: 1315000. Mean Reward: -0.20527857142857467. Std of Reward: 1.6960691343074423.\n",
      "Step: 1320000. Mean Reward: -0.2341641025641025. Std of Reward: 1.0467648300743606.\n",
      "Saved Model\n",
      "Step: 1325000. Mean Reward: -0.21543061224489782. Std of Reward: 1.1149504211918806.\n",
      "Step: 1330000. Mean Reward: -0.011689743589743506. Std of Reward: 0.9355350608882684.\n",
      "Step: 1335000. Mean Reward: 0.06060172413793111. Std of Reward: 0.9934727718691153.\n",
      "Step: 1340000. Mean Reward: 0.2147208333333334. Std of Reward: 0.8492918160047458.\n",
      "Saved Model\n",
      "Step: 1345000. Mean Reward: -0.27980000000000477. Std of Reward: 1.649324346007603.\n",
      "Step: 1350000. Mean Reward: -0.2874771428571427. Std of Reward: 1.0364282052416405.\n",
      "Step: 1355000. Mean Reward: -0.08997380952381293. Std of Reward: 1.448073032238037.\n",
      "Step: 1360000. Mean Reward: -0.5414314285714376. Std of Reward: 2.1263743771663326.\n",
      "Saved Model\n",
      "Step: 1365000. Mean Reward: -0.07791578947368412. Std of Reward: 0.840376575842269.\n",
      "Step: 1370000. Mean Reward: 0.08497457627118608. Std of Reward: 1.228343519775302.\n",
      "Step: 1375000. Mean Reward: 0.08398260869565222. Std of Reward: 0.993510441139933.\n",
      "Step: 1380000. Mean Reward: -0.014818518518518495. Std of Reward: 0.9928425991536128.\n",
      "Saved Model\n",
      "Step: 1385000. Mean Reward: 0.03314029850746271. Std of Reward: 1.0855670351383262.\n",
      "Step: 1390000. Mean Reward: -0.9321812500000042. Std of Reward: 1.6267588420763197.\n",
      "Step: 1395000. Mean Reward: 0.07208000000000012. Std of Reward: 1.0181483972539411.\n",
      "Step: 1400000. Mean Reward: -0.030521666666666534. Std of Reward: 0.9861768861098004.\n",
      "Saved Model\n",
      "Step: 1405000. Mean Reward: -0.21874561403508763. Std of Reward: 0.9261219672754971.\n",
      "Step: 1410000. Mean Reward: 0.13222876712328777. Std of Reward: 0.8914267810004259.\n",
      "Step: 1415000. Mean Reward: -0.12830169491525417. Std of Reward: 1.0838715732434645.\n",
      "Step: 1420000. Mean Reward: -0.1684462962962975. Std of Reward: 1.441835551535431.\n",
      "Saved Model\n",
      "Step: 1425000. Mean Reward: -0.11835333333333323. Std of Reward: 0.9776418383823166.\n",
      "Step: 1430000. Mean Reward: 0.03355636363636233. Std of Reward: 1.249665421370302.\n",
      "Step: 1435000. Mean Reward: 0.08546599999999996. Std of Reward: 1.1685103735286224.\n",
      "Step: 1440000. Mean Reward: 0.015836734693877655. Std of Reward: 0.9646161545347133.\n",
      "Saved Model\n",
      "Step: 1445000. Mean Reward: -0.20854242424242914. Std of Reward: 1.7700611581679342.\n",
      "Step: 1450000. Mean Reward: 0.06487090909090916. Std of Reward: 1.0096255649177754.\n",
      "Step: 1455000. Mean Reward: -0.04009795918367549. Std of Reward: 1.2664643563536357.\n",
      "Step: 1460000. Mean Reward: -0.20141052631578935. Std of Reward: 0.8984213528504417.\n",
      "Saved Model\n",
      "Step: 1465000. Mean Reward: -0.20135348837209527. Std of Reward: 1.41011199396045.\n",
      "Step: 1470000. Mean Reward: 0.06426666666666678. Std of Reward: 0.9817078667075839.\n",
      "Step: 1475000. Mean Reward: -0.4288923076923142. Std of Reward: 2.0245565827132586.\n",
      "Step: 1480000. Mean Reward: -0.32832653061224704. Std of Reward: 1.6023071537662326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "Step: 1485000. Mean Reward: 0.1364773333333334. Std of Reward: 0.9711751152184427.\n",
      "Step: 1490000. Mean Reward: 0.11331129032258072. Std of Reward: 0.8845396893126406.\n",
      "Step: 1495000. Mean Reward: 0.0924333333333334. Std of Reward: 0.9505010476518696.\n",
      "Step: 1500000. Mean Reward: -0.16074901960784313. Std of Reward: 1.1021786013009445.\n",
      "Saved Model\n",
      "Step: 1505000. Mean Reward: 0.15973333333333342. Std of Reward: 0.9653494513031605.\n",
      "Step: 1510000. Mean Reward: -0.09358833333333486. Std of Reward: 1.2509353196830661.\n",
      "Step: 1515000. Mean Reward: -0.27101020408163257. Std of Reward: 1.0336705254586682.\n",
      "Step: 1520000. Mean Reward: -0.4346000000000036. Std of Reward: 1.5583112746331194.\n",
      "Saved Model\n",
      "Step: 1525000. Mean Reward: -0.049509999999999936. Std of Reward: 0.940295654408761.\n",
      "Step: 1530000. Mean Reward: 0.012048648648648692. Std of Reward: 1.065445367255535.\n",
      "Step: 1535000. Mean Reward: -0.04927857142857149. Std of Reward: 0.9505568491517948.\n",
      "Step: 1540000. Mean Reward: -0.35254500000000366. Std of Reward: 1.6490190817498325.\n",
      "Saved Model\n",
      "Step: 1545000. Mean Reward: 0.031116216216213816. Std of Reward: 1.2981838058576753.\n",
      "Step: 1550000. Mean Reward: -0.48626000000000236. Std of Reward: 1.5461748090414338.\n",
      "Step: 1555000. Mean Reward: 0.17599499999999946. Std of Reward: 1.0792955587519448.\n",
      "Step: 1560000. Mean Reward: -0.7208419354838822. Std of Reward: 2.2299839511608828.\n",
      "Saved Model\n",
      "Step: 1565000. Mean Reward: -0.27655405405405825. Std of Reward: 1.5229319667853194.\n",
      "Step: 1570000. Mean Reward: -0.16702884615384883. Std of Reward: 1.750241403386827.\n",
      "Step: 1575000. Mean Reward: -0.10422682926829421. Std of Reward: 1.262847252417625.\n",
      "Step: 1580000. Mean Reward: -0.03428867924528294. Std of Reward: 1.0317569202643373.\n",
      "Saved Model\n",
      "Step: 1585000. Mean Reward: -0.045059999999999906. Std of Reward: 0.8897158840888477.\n",
      "Step: 1590000. Mean Reward: 0.026022000000000087. Std of Reward: 0.9663083216634325.\n",
      "Step: 1595000. Mean Reward: 0.04333770491803283. Std of Reward: 0.9837454465766573.\n",
      "Step: 1600000. Mean Reward: 0.036134545454545516. Std of Reward: 1.0462581282783088.\n",
      "Saved Model\n",
      "Step: 1605000. Mean Reward: -0.35039473684211037. Std of Reward: 1.7852219289942195.\n",
      "Step: 1610000. Mean Reward: -0.17143846153846215. Std of Reward: 1.333111574353236.\n",
      "Step: 1615000. Mean Reward: -0.08643478260869557. Std of Reward: 0.996083703968652.\n",
      "Step: 1620000. Mean Reward: -0.05329803921568907. Std of Reward: 1.499927610866385.\n",
      "Saved Model\n",
      "Step: 1625000. Mean Reward: 0.1880828947368422. Std of Reward: 0.9085464250207231.\n",
      "Step: 1630000. Mean Reward: -0.20255121951219504. Std of Reward: 1.0466971421459799.\n",
      "Step: 1635000. Mean Reward: -0.08722599999999989. Std of Reward: 0.9079818821562465.\n",
      "Step: 1640000. Mean Reward: -0.22649795918367438. Std of Reward: 1.3039725990125086.\n",
      "Saved Model\n",
      "Step: 1645000. Mean Reward: 0.15092656250000008. Std of Reward: 0.8926158251597849.\n",
      "Step: 1650000. Mean Reward: 0.014941666666666758. Std of Reward: 1.0092584466315961.\n",
      "Step: 1655000. Mean Reward: -0.3423500000000068. Std of Reward: 2.183596480613387.\n",
      "Step: 1660000. Mean Reward: 0.031901612903225914. Std of Reward: 0.9523167154945364.\n",
      "Saved Model\n",
      "Step: 1665000. Mean Reward: -0.22058275862069207. Std of Reward: 1.4726682963526025.\n",
      "Step: 1670000. Mean Reward: -0.3259478260869605. Std of Reward: 1.721579225183172.\n",
      "Step: 1675000. Mean Reward: 0.07660476190476198. Std of Reward: 0.9533614454610645.\n",
      "Step: 1680000. Mean Reward: -0.09787692307692786. Std of Reward: 1.627265079419541.\n",
      "Saved Model\n",
      "Step: 1685000. Mean Reward: 0.05801454545454552. Std of Reward: 0.9371055746127263.\n",
      "Step: 1690000. Mean Reward: 0.07972758620689667. Std of Reward: 0.9650783914547016.\n",
      "Step: 1695000. Mean Reward: 0.0478660377358462. Std of Reward: 1.363511280639627.\n",
      "Step: 1700000. Mean Reward: 0.24012500000000012. Std of Reward: 0.6867302613654068.\n",
      "Saved Model\n",
      "Step: 1705000. Mean Reward: 0.34029318181818186. Std of Reward: 0.7588533019083127.\n",
      "Step: 1710000. Mean Reward: 0.16522272727272738. Std of Reward: 0.8134342639428206.\n",
      "Step: 1715000. Mean Reward: -0.037102272727273. Std of Reward: 1.231100858708587.\n",
      "Step: 1720000. Mean Reward: 0.06900508474576278. Std of Reward: 0.9152044619986733.\n",
      "Saved Model\n",
      "Step: 1725000. Mean Reward: -0.05175777777777771. Std of Reward: 1.0447292737012759.\n",
      "Step: 1730000. Mean Reward: 0.17793750000000008. Std of Reward: 0.8450931530569574.\n",
      "Step: 1735000. Mean Reward: -0.01045434782608689. Std of Reward: 0.9319517604390498.\n",
      "Step: 1740000. Mean Reward: -0.176835135135137. Std of Reward: 1.4944843811570263.\n",
      "Saved Model\n",
      "Step: 1745000. Mean Reward: -0.08200454545454629. Std of Reward: 1.156048986056026.\n",
      "Step: 1750000. Mean Reward: 0.23352571428571436. Std of Reward: 0.899348584998484.\n",
      "Step: 1755000. Mean Reward: -0.279255813953491. Std of Reward: 1.764375052585809.\n",
      "Step: 1760000. Mean Reward: -0.2249476190476227. Std of Reward: 1.6259468626352587.\n",
      "Saved Model\n",
      "Step: 1765000. Mean Reward: 0.18865303030302993. Std of Reward: 1.0804597519209702.\n",
      "Step: 1770000. Mean Reward: -0.3294730769230834. Std of Reward: 1.747513030557299.\n",
      "Step: 1775000. Mean Reward: -0.5234192307692375. Std of Reward: 1.8976497234979417.\n",
      "Step: 1780000. Mean Reward: -0.31274166666666964. Std of Reward: 1.4779458813718185.\n",
      "Saved Model\n",
      "Step: 1785000. Mean Reward: 0.0037074074074074843. Std of Reward: 0.8860975336859873.\n",
      "Step: 1790000. Mean Reward: 0.0707444444444445. Std of Reward: 1.05485736119588.\n",
      "Step: 1795000. Mean Reward: -0.20308378378378736. Std of Reward: 1.746071973612312.\n",
      "Step: 1800000. Mean Reward: -0.3000666666666715. Std of Reward: 2.017072999914531.\n",
      "Saved Model\n",
      "Step: 1805000. Mean Reward: -0.0960211538461538. Std of Reward: 1.1043007662938256.\n",
      "Step: 1810000. Mean Reward: 0.04627678571428504. Std of Reward: 1.2426198992151187.\n",
      "Step: 1815000. Mean Reward: 0.13737777777777782. Std of Reward: 1.0206901119788305.\n",
      "Step: 1820000. Mean Reward: -0.17754042553191623. Std of Reward: 1.3566160258368174.\n",
      "Saved Model\n",
      "Step: 1825000. Mean Reward: -0.2523620689655189. Std of Reward: 1.47658744860873.\n",
      "Step: 1830000. Mean Reward: -0.14702173913043468. Std of Reward: 1.0616482285891784.\n",
      "Step: 1835000. Mean Reward: 0.01703684210526326. Std of Reward: 0.9903062695903866.\n",
      "Step: 1840000. Mean Reward: -0.005279310344827494. Std of Reward: 0.9997392414781209.\n",
      "Saved Model\n",
      "Step: 1845000. Mean Reward: -0.3212600000000021. Std of Reward: 1.6455865319089242.\n",
      "Step: 1850000. Mean Reward: -0.09504255319148928. Std of Reward: 1.0863351690274146.\n",
      "Step: 1855000. Mean Reward: 0.28586111111111123. Std of Reward: 0.7580396230767367.\n",
      "Step: 1860000. Mean Reward: -0.21481142857143162. Std of Reward: 1.5707491635288486.\n",
      "Saved Model\n",
      "Step: 1865000. Mean Reward: 0.10456470588235302. Std of Reward: 0.8355250412983912.\n",
      "Step: 1870000. Mean Reward: -0.19620400000000238. Std of Reward: 1.3115454765977554.\n",
      "Step: 1875000. Mean Reward: 0.07847027027026672. Std of Reward: 1.5036420449649794.\n",
      "Step: 1880000. Mean Reward: -0.04294081632653052. Std of Reward: 0.9741227385512561.\n",
      "Saved Model\n",
      "Step: 1885000. Mean Reward: -0.2904555555555555. Std of Reward: 1.1304586938358854.\n",
      "Step: 1890000. Mean Reward: -0.09590576923076916. Std of Reward: 1.2513819244851887.\n",
      "Step: 1895000. Mean Reward: 0.004451111111111198. Std of Reward: 1.0620177493018177.\n",
      "Step: 1900000. Mean Reward: 0.13935609756097295. Std of Reward: 1.3839286441933896.\n",
      "Saved Model\n",
      "Step: 1905000. Mean Reward: -0.00860784313725485. Std of Reward: 0.9083499625410292.\n",
      "Step: 1910000. Mean Reward: 0.0705469387755103. Std of Reward: 0.8669791634391034.\n",
      "Step: 1915000. Mean Reward: 0.17466527777777785. Std of Reward: 0.8498582968745964.\n",
      "Step: 1920000. Mean Reward: -0.09833658536585359. Std of Reward: 0.9913787452161705.\n",
      "Saved Model\n",
      "Step: 1925000. Mean Reward: -0.011176363636365292. Std of Reward: 1.2366235351242358.\n",
      "Step: 1930000. Mean Reward: 0.01027301587301572. Std of Reward: 1.2675850297650877.\n",
      "Step: 1935000. Mean Reward: -0.058198039215686205. Std of Reward: 0.9744961025667183.\n",
      "Step: 1940000. Mean Reward: -0.5969941176470652. Std of Reward: 1.9488431642359054.\n",
      "Saved Model\n",
      "Step: 1945000. Mean Reward: -0.0466924528301886. Std of Reward: 0.9682682810533368.\n",
      "Step: 1950000. Mean Reward: -0.1753733333333332. Std of Reward: 1.19406308932522.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1955000. Mean Reward: -0.12809750000000197. Std of Reward: 1.4024698282828683.\n",
      "Step: 1960000. Mean Reward: 0.3250179487179488. Std of Reward: 0.7687073670052212.\n",
      "Saved Model\n",
      "Step: 1965000. Mean Reward: 0.17710000000000006. Std of Reward: 0.9764010998584947.\n",
      "Step: 1970000. Mean Reward: 0.030511538461538548. Std of Reward: 0.9070883564489876.\n",
      "Step: 1975000. Mean Reward: -0.13764210526316045. Std of Reward: 1.4747528375668209.\n",
      "Step: 1980000. Mean Reward: 0.25530208333333343. Std of Reward: 0.8486188964747328.\n",
      "Saved Model\n",
      "Step: 1985000. Mean Reward: -0.33685000000000775. Std of Reward: 1.8213706562641505.\n",
      "Step: 1990000. Mean Reward: -0.4307921052631609. Std of Reward: 2.056129605322851.\n",
      "Step: 1995000. Mean Reward: -0.3482684210526315. Std of Reward: 1.1319410011371625.\n",
      "Step: 2000000. Mean Reward: 0.25925344827586216. Std of Reward: 0.8646351285898333.\n",
      "Saved Model\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons4/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons4/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons4/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons4/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
