{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmu/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 2e6 # Set maximum number of steps to run environment.\n",
    "run_path = \"scifibuttons18\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 5000 # Frequency at which to save training statistics.\n",
    "save_freq = 20000 # Frequency at which to save model.\n",
    "env_name = \"scifibuttons18\" # Name of the training environment file.\n",
    "curriculum_file = 'curricula/lessons17.json'\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 1e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 3 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 2048 #2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 256 # Number of units in hidden layer.\n",
    "batch_size = 64 #64 # How many experiences per gradient descent update step.\n",
    "normalize = True\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\tlessonNr -> 1.0\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 30\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 5\n",
      "        Memory space size (per agent): 9\n",
      "        Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Mean Reward: -1.2363865469831934. Std of Reward: 2.899766060968979.\n",
      "Step: 10000. Mean Reward: -1.042022892812977. Std of Reward: 2.796795069289543.\n",
      "Step: 15000. Mean Reward: -1.1132669235139443. Std of Reward: 2.630413073942896.\n",
      "Step: 20000. Mean Reward: -1.1833333232570282. Std of Reward: 2.882403555221491.\n",
      "Saved Model\n",
      "Step: 25000. Mean Reward: -1.145341357188755. Std of Reward: 2.809801676710516.\n",
      "Step: 30000. Mean Reward: -0.7320422454330985. Std of Reward: 2.497174321650922.\n",
      "Step: 35000. Mean Reward: -0.791851845191919. Std of Reward: 2.5632881280111786.\n",
      "Step: 40000. Mean Reward: -0.6534394837738853. Std of Reward: 2.255912032170483.\n",
      "Saved Model\n",
      "Step: 45000. Mean Reward: -0.48533332600289864. Std of Reward: 2.168270513309537.\n",
      "Step: 50000. Mean Reward: -0.41208091786705214. Std of Reward: 2.131137913504407.\n",
      "Step: 55000. Mean Reward: -0.3388802020364583. Std of Reward: 2.1224121541705574.\n",
      "Step: 60000. Mean Reward: -0.3225668393957219. Std of Reward: 2.1750716551794294.\n",
      "Saved Model\n",
      "Step: 65000. Mean Reward: -0.03595603783296708. Std of Reward: 1.8232254658488964.\n",
      "Step: 70000. Mean Reward: 0.17677355245891782. Std of Reward: 1.594630579474702.\n",
      "Step: 75000. Mean Reward: 0.19930657403832114. Std of Reward: 1.4531425352505438.\n",
      "Step: 80000. Mean Reward: 0.4214939062621951. Std of Reward: 1.2025123169884107.\n",
      "Saved Model\n",
      "Step: 85000. Mean Reward: 0.442180454481203. Std of Reward: 1.2313071070870085.\n",
      "Step: 90000. Mean Reward: 0.387861274933526. Std of Reward: 1.2578663632254274.\n",
      "Step: 95000. Mean Reward: 0.482676633236413. Std of Reward: 1.105567569803506.\n",
      "Step: 100000. Mean Reward: 0.5504986554986523. Std of Reward: 1.0000744657862635.\n",
      "Saved Model\n",
      "Step: 105000. Mean Reward: 0.6496774219714639. Std of Reward: 0.8671669685275019.\n",
      "Step: 110000. Mean Reward: 0.6570709407871854. Std of Reward: 0.906669350002022.\n",
      "Step: 115000. Mean Reward: 0.6867144452271223. Std of Reward: 0.8054576838766941.\n",
      "Step: 120000. Mean Reward: 0.7685098057205882. Std of Reward: 0.6339214506079999.\n",
      "Saved Model\n",
      "Step: 125000. Mean Reward: 0.7511410803008299. Std of Reward: 0.705214235995389.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 1 : \tlessonNr -> 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 130000. Mean Reward: 0.5393586030947521. Std of Reward: 0.7845905828095262.\n",
      "Step: 135000. Mean Reward: 0.4051125435562701. Std of Reward: 0.8951860703616557.\n",
      "Step: 140000. Mean Reward: 0.4516033089024793. Std of Reward: 0.9052618808844657.\n",
      "Saved Model\n",
      "Step: 145000. Mean Reward: 0.46099518756500796. Std of Reward: 0.8443307091891284.\n",
      "Step: 150000. Mean Reward: 0.4456067611213517. Std of Reward: 0.9159018713324486.\n",
      "Step: 155000. Mean Reward: 0.4753166441708394. Std of Reward: 0.8547778778784244.\n",
      "Step: 160000. Mean Reward: 0.4892608106652719. Std of Reward: 0.8403322593089297.\n",
      "Saved Model\n",
      "Step: 165000. Mean Reward: 0.5216193198849431. Std of Reward: 0.8173658069427604.\n",
      "Step: 170000. Mean Reward: 0.523597952909091. Std of Reward: 0.8336576825837417.\n",
      "Step: 175000. Mean Reward: 0.5690765183007915. Std of Reward: 0.7918877552571919.\n",
      "Step: 180000. Mean Reward: 0.5104928675940337. Std of Reward: 0.8324288308389558.\n",
      "Saved Model\n",
      "Step: 185000. Mean Reward: 0.4776170810261708. Std of Reward: 0.8647254508986986.\n",
      "Step: 190000. Mean Reward: 0.6306332146905614. Std of Reward: 0.7454577413715473.\n",
      "Step: 195000. Mean Reward: 0.5929510165734766. Std of Reward: 0.7899829921695738.\n",
      "Step: 200000. Mean Reward: 0.6164927194332523. Std of Reward: 0.7423525669170885.\n",
      "Saved Model\n",
      "Step: 205000. Mean Reward: 0.6103941447601351. Std of Reward: 0.7500149859828916.\n",
      "Step: 210000. Mean Reward: 0.5981243193838603. Std of Reward: 0.7923665058891118.\n",
      "Step: 215000. Mean Reward: 0.6022342739262473. Std of Reward: 0.7856102788805236.\n",
      "Step: 220000. Mean Reward: 0.6155124062847895. Std of Reward: 0.7427076117674561.\n",
      "Saved Model\n",
      "Step: 225000. Mean Reward: 0.6384687507718749. Std of Reward: 0.7401044744160485.\n",
      "Step: 230000. Mean Reward: 0.6457036252995736. Std of Reward: 0.7028190153980572.\n",
      "Step: 235000. Mean Reward: 0.6134417633871984. Std of Reward: 0.7826853378976641.\n",
      "Step: 240000. Mean Reward: 0.5896570209324759. Std of Reward: 0.7918444758124304.\n",
      "Saved Model\n",
      "Step: 245000. Mean Reward: 0.6246750529486372. Std of Reward: 0.7513806641087946.\n",
      "Step: 250000. Mean Reward: 0.6404908569162655. Std of Reward: 0.736392534432551.\n",
      "Step: 255000. Mean Reward: 0.6331692917588583. Std of Reward: 0.7441583487152988.\n",
      "Step: 260000. Mean Reward: 0.6304901964882353. Std of Reward: 0.7614119716244231.\n",
      "Saved Model\n",
      "Step: 265000. Mean Reward: 0.6137703352956938. Std of Reward: 0.7649055634986228.\n",
      "Step: 270000. Mean Reward: 0.652401501368668. Std of Reward: 0.712894143460076.\n",
      "Step: 275000. Mean Reward: 0.6549952789499528. Std of Reward: 0.7203543316139056.\n",
      "Step: 280000. Mean Reward: 0.6604813808474114. Std of Reward: 0.7235605801868725.\n",
      "Saved Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 2 : \tlessonNr -> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 285000. Mean Reward: -4.127426750228001. Std of Reward: 28.595461372630467.\n",
      "Step: 290000. Mean Reward: -7.707837856945919. Std of Reward: 36.18073468681037.\n",
      "Step: 295000. Mean Reward: -9.030654782499973. Std of Reward: 34.488299867390445.\n",
      "Step: 300000. Mean Reward: -5.853831778233626. Std of Reward: 22.656732290556526.\n",
      "Saved Model\n",
      "Step: 305000. Mean Reward: -6.151690153624386. Std of Reward: 31.82716897386048.\n",
      "Step: 310000. Mean Reward: -7.961801244565198. Std of Reward: 27.6733828536603.\n",
      "Step: 315000. Mean Reward: -6.44302856927998. Std of Reward: 24.211204930239578.\n",
      "Step: 320000. Mean Reward: -6.865260422286435. Std of Reward: 29.001655031270875.\n",
      "Saved Model\n",
      "Step: 325000. Mean Reward: -6.840432093228388. Std of Reward: 23.050119737049656.\n",
      "Step: 330000. Mean Reward: -4.849518062951809. Std of Reward: 16.241245655604775.\n",
      "Step: 335000. Mean Reward: -10.231085256403093. Std of Reward: 29.82305402102078.\n",
      "Step: 340000. Mean Reward: -8.76878574006427. Std of Reward: 29.56410498358291.\n",
      "Saved Model\n",
      "Step: 345000. Mean Reward: -7.461344525899148. Std of Reward: 23.281265292658823.\n",
      "Step: 350000. Mean Reward: -10.967920813138587. Std of Reward: 36.50194011865017.\n",
      "Step: 355000. Mean Reward: -9.394711518980769. Std of Reward: 28.358696010464477.\n",
      "Step: 360000. Mean Reward: -11.917547191179223. Std of Reward: 33.37905019726824.\n",
      "Saved Model\n",
      "Step: 365000. Mean Reward: -8.250748380952375. Std of Reward: 27.849531200702906.\n",
      "Step: 370000. Mean Reward: -9.347767848946406. Std of Reward: 32.12301070479875.\n",
      "Step: 375000. Mean Reward: -8.958256884403665. Std of Reward: 31.57073180086636.\n",
      "Step: 380000. Mean Reward: -7.565882330637264. Std of Reward: 23.097954471993088.\n",
      "Saved Model\n",
      "Step: 385000. Mean Reward: -6.576083309258333. Std of Reward: 23.50266969161461.\n",
      "Step: 390000. Mean Reward: -5.7349484524020635. Std of Reward: 19.47633388706531.\n",
      "Step: 395000. Mean Reward: -5.730241925112917. Std of Reward: 17.206134782652956.\n",
      "Step: 400000. Mean Reward: -8.227964594734523. Std of Reward: 20.01198030527466.\n",
      "Saved Model\n",
      "Step: 405000. Mean Reward: -7.9773737294646345. Std of Reward: 23.042975158528858.\n",
      "Step: 410000. Mean Reward: -8.452891563469855. Std of Reward: 39.43227878856602.\n",
      "Step: 415000. Mean Reward: -13.030416679847194. Std of Reward: 37.62967708590595.\n",
      "Step: 420000. Mean Reward: -7.6787209076860705. Std of Reward: 19.846065550469987.\n",
      "Saved Model\n",
      "Step: 425000. Mean Reward: -7.12097828863045. Std of Reward: 21.011932760004672.\n",
      "Step: 430000. Mean Reward: -11.60732138473216. Std of Reward: 21.126483780218468.\n",
      "Step: 435000. Mean Reward: -9.072999994479995. Std of Reward: 17.025405139531614.\n",
      "Step: 440000. Mean Reward: -12.898888881698385. Std of Reward: 36.74899965105941.\n",
      "Saved Model\n",
      "Step: 445000. Mean Reward: -7.991076907661519. Std of Reward: 18.4153758389289.\n",
      "Step: 450000. Mean Reward: -9.632784784430376. Std of Reward: 27.22469437082878.\n",
      "Step: 455000. Mean Reward: -9.995797098550748. Std of Reward: 23.62396844622427.\n",
      "Step: 460000. Mean Reward: -14.388431447823546. Std of Reward: 32.6241980141908.\n",
      "Saved Model\n",
      "Step: 465000. Mean Reward: -7.055285713000011. Std of Reward: 19.24376416360275.\n",
      "Step: 470000. Mean Reward: -12.364749994975002. Std of Reward: 18.463267986012724.\n",
      "Step: 475000. Mean Reward: -10.270196035039238. Std of Reward: 20.98331705602756.\n",
      "Step: 480000. Mean Reward: -8.789749954149984. Std of Reward: 16.065369742594246.\n",
      "Saved Model\n",
      "Step: 485000. Mean Reward: -8.943818149672726. Std of Reward: 22.007016237930998.\n",
      "Step: 490000. Mean Reward: -13.817241220275829. Std of Reward: 21.876081079928962.\n",
      "Step: 495000. Mean Reward: -18.358709481387173. Std of Reward: 29.631052383115335.\n",
      "Step: 500000. Mean Reward: -18.044482755000054. Std of Reward: 26.32280859395045.\n",
      "Saved Model\n",
      "Step: 505000. Mean Reward: -19.366818180045392. Std of Reward: 28.45730157045127.\n",
      "Step: 510000. Mean Reward: -16.982758604965507. Std of Reward: 26.801127322753413.\n",
      "Step: 515000. Mean Reward: -33.19649985120002. Std of Reward: 34.54625725060189.\n",
      "Step: 520000. Mean Reward: -24.408888857388884. Std of Reward: 31.01298813469026.\n",
      "Saved Model\n",
      "Step: 525000. Mean Reward: -12.253749986499969. Std of Reward: 18.918504296984533.\n",
      "Step: 530000. Mean Reward: -17.027241234379375. Std of Reward: 23.249244848521954.\n",
      "Step: 535000. Mean Reward: -11.362702644729714. Std of Reward: 15.158113720009373.\n",
      "Step: 540000. Mean Reward: -17.853076860717994. Std of Reward: 25.516572267261665.\n",
      "Saved Model\n",
      "Step: 545000. Mean Reward: -11.58628563165714. Std of Reward: 20.503930358814504.\n",
      "Step: 550000. Mean Reward: -28.73882344152936. Std of Reward: 33.30156669611153.\n",
      "Step: 555000. Mean Reward: -7.23061218904082. Std of Reward: 16.252633437665676.\n",
      "Step: 560000. Mean Reward: -7.832051279769207. Std of Reward: 14.943943662402736.\n",
      "Saved Model\n",
      "Step: 565000. Mean Reward: -11.909074092944449. Std of Reward: 29.148576005724188.\n",
      "Step: 570000. Mean Reward: -9.443513508648625. Std of Reward: 18.305781132162245.\n",
      "Step: 575000. Mean Reward: -12.322499998406247. Std of Reward: 22.233286699237254.\n",
      "Step: 580000. Mean Reward: -15.012432353810885. Std of Reward: 27.083663539192646.\n",
      "Saved Model\n",
      "Step: 585000. Mean Reward: -14.695999999422282. Std of Reward: 27.741205325372004.\n",
      "Step: 590000. Mean Reward: -9.765675636594594. Std of Reward: 18.531637944206313.\n",
      "Step: 595000. Mean Reward: -8.722586204137928. Std of Reward: 16.481727781109317.\n",
      "Step: 600000. Mean Reward: -16.678139653627927. Std of Reward: 37.180162003319076.\n",
      "Saved Model\n",
      "Step: 605000. Mean Reward: -11.132571427342864. Std of Reward: 20.414982640302387.\n",
      "Step: 610000. Mean Reward: -21.12444437727768. Std of Reward: 24.36708362049555.\n",
      "Step: 615000. Mean Reward: -8.078787865090877. Std of Reward: 9.318717797480545.\n",
      "Step: 620000. Mean Reward: -20.64142856821434. Std of Reward: 29.235066851215716.\n",
      "Saved Model\n",
      "Step: 625000. Mean Reward: -8.638599999079997. Std of Reward: 15.435330512402142.\n",
      "Step: 630000. Mean Reward: -17.639473664631577. Std of Reward: 38.43800853006897.\n",
      "Step: 635000. Mean Reward: -11.029047626809506. Std of Reward: 16.88673301778129.\n",
      "Step: 640000. Mean Reward: -13.645348835883725. Std of Reward: 22.833425755820056.\n",
      "Saved Model\n",
      "Step: 645000. Mean Reward: -15.424999988374994. Std of Reward: 20.3447947875055.\n",
      "Step: 650000. Mean Reward: -9.890888885911131. Std of Reward: 18.746040746136238.\n",
      "Step: 655000. Mean Reward: -15.121568631019642. Std of Reward: 27.03136422671347.\n",
      "Step: 660000. Mean Reward: -5.890740690777783. Std of Reward: 11.076288563921324.\n",
      "Saved Model\n",
      "Step: 665000. Mean Reward: -10.638387096629016. Std of Reward: 30.473428626273442.\n",
      "Step: 670000. Mean Reward: -6.120483870419343. Std of Reward: 12.037215066066318.\n",
      "Step: 675000. Mean Reward: -5.1829999988666735. Std of Reward: 13.451157691001983.\n",
      "Step: 680000. Mean Reward: -7.118867931320749. Std of Reward: 15.338688776842568.\n",
      "Saved Model\n",
      "Step: 685000. Mean Reward: -7.299722220694453. Std of Reward: 18.580445065191945.\n",
      "Step: 690000. Mean Reward: -6.731403482456131. Std of Reward: 10.29665914726868.\n",
      "Step: 695000. Mean Reward: -6.650746267074631. Std of Reward: 15.172526065627071.\n",
      "Step: 700000. Mean Reward: -8.770599999499987. Std of Reward: 15.824351792372417.\n",
      "Saved Model\n",
      "Step: 705000. Mean Reward: -9.200249987549975. Std of Reward: 12.781432883085161.\n",
      "Step: 710000. Mean Reward: -7.469298240350871. Std of Reward: 13.43891493099285.\n",
      "Step: 715000. Mean Reward: -6.937818174981802. Std of Reward: 13.023595303889627.\n",
      "Step: 720000. Mean Reward: -7.494444444244419. Std of Reward: 11.633820726286901.\n",
      "Saved Model\n",
      "Step: 725000. Mean Reward: -7.125925924722211. Std of Reward: 11.886556446584352.\n",
      "Step: 730000. Mean Reward: -10.193898300355904. Std of Reward: 30.972885956845722.\n",
      "Step: 735000. Mean Reward: -14.4283333158333. Std of Reward: 31.159699751886535.\n",
      "Step: 740000. Mean Reward: -4.993194440277776. Std of Reward: 8.097918077222614.\n",
      "Saved Model\n",
      "Step: 745000. Mean Reward: -5.819594582189176. Std of Reward: 10.889878067253434.\n",
      "Step: 750000. Mean Reward: -6.219999994719979. Std of Reward: 8.874964111710868.\n",
      "Step: 755000. Mean Reward: -5.365499984849981. Std of Reward: 9.727113034260125.\n",
      "Step: 760000. Mean Reward: -6.447187492218736. Std of Reward: 10.9097365991798.\n",
      "Saved Model\n",
      "Step: 765000. Mean Reward: -6.482580653661271. Std of Reward: 9.377999307973218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 770000. Mean Reward: -10.285641039487142. Std of Reward: 19.010336909356095.\n",
      "Step: 775000. Mean Reward: -11.786562497906193. Std of Reward: 18.33429873293699.\n",
      "Step: 780000. Mean Reward: -8.499374999906191. Std of Reward: 12.483518118348861.\n",
      "Saved Model\n",
      "Step: 785000. Mean Reward: -5.050895505447749. Std of Reward: 9.226537884773704.\n",
      "Step: 790000. Mean Reward: -5.6337930977758495. Std of Reward: 8.080356517949564.\n",
      "Step: 795000. Mean Reward: -10.476607146517852. Std of Reward: 39.627422517581415.\n",
      "Step: 800000. Mean Reward: -6.15411763090194. Std of Reward: 8.427813927035187.\n",
      "Saved Model\n",
      "Step: 805000. Mean Reward: -6.385147042044095. Std of Reward: 11.354978415306801.\n",
      "Step: 810000. Mean Reward: -4.487361114583319. Std of Reward: 8.027577835216468.\n",
      "Step: 815000. Mean Reward: -5.416266674426654. Std of Reward: 9.994953392099708.\n",
      "Step: 820000. Mean Reward: -5.005762711118627. Std of Reward: 7.776605552379795.\n",
      "Saved Model\n",
      "Step: 825000. Mean Reward: -4.620684939808209. Std of Reward: 7.866932796222857.\n",
      "Step: 830000. Mean Reward: -5.0423529358823345. Std of Reward: 7.172720537251576.\n",
      "Step: 835000. Mean Reward: -6.406562489843734. Std of Reward: 11.61379842055808.\n",
      "Step: 840000. Mean Reward: -6.168135583423712. Std of Reward: 8.947820570108004.\n",
      "Saved Model\n",
      "Step: 845000. Mean Reward: -5.082083330611102. Std of Reward: 9.172993715938734.\n",
      "Step: 850000. Mean Reward: -3.9971604748518503. Std of Reward: 7.304494106417848.\n",
      "Step: 855000. Mean Reward: -4.769705886500004. Std of Reward: 8.063969978078728.\n",
      "Step: 860000. Mean Reward: -5.619999999830169. Std of Reward: 11.348913670992069.\n",
      "Saved Model\n",
      "Step: 865000. Mean Reward: -4.585303030045446. Std of Reward: 6.677913668724517.\n",
      "Step: 870000. Mean Reward: -4.178571427946423. Std of Reward: 6.69496223975257.\n",
      "Step: 875000. Mean Reward: -7.039148948234039. Std of Reward: 9.079764940881093.\n",
      "Step: 880000. Mean Reward: -5.340793649984109. Std of Reward: 10.454331265906228.\n",
      "Saved Model\n",
      "Step: 885000. Mean Reward: -3.3729999987374923. Std of Reward: 5.440923955855903.\n",
      "Step: 890000. Mean Reward: -7.292830210754707. Std of Reward: 11.452173033383241.\n",
      "Step: 895000. Mean Reward: -3.7696969629545407. Std of Reward: 7.129981066056876.\n",
      "Step: 900000. Mean Reward: -3.7393670793417684. Std of Reward: 6.71933169822587.\n",
      "Saved Model\n",
      "Step: 905000. Mean Reward: -8.364864855675647. Std of Reward: 13.080169560859204.\n",
      "Step: 910000. Mean Reward: -8.59893616772336. Std of Reward: 20.122516787951685.\n",
      "Step: 915000. Mean Reward: -5.590454540196955. Std of Reward: 10.305817924376976.\n",
      "Step: 920000. Mean Reward: -4.353283580164166. Std of Reward: 6.869156977688117.\n",
      "Saved Model\n",
      "Step: 925000. Mean Reward: -7.557321421696436. Std of Reward: 20.88465965354725.\n",
      "Step: 930000. Mean Reward: -3.6224242421060566. Std of Reward: 6.777380619691267.\n",
      "Step: 935000. Mean Reward: -5.534912274298239. Std of Reward: 9.549940405678413.\n",
      "Step: 940000. Mean Reward: -4.112033895576262. Std of Reward: 6.7670194180441126.\n",
      "Saved Model\n",
      "Step: 945000. Mean Reward: -4.5793749998125035. Std of Reward: 9.9385717779449.\n",
      "Step: 950000. Mean Reward: -5.863207570283004. Std of Reward: 8.43059996647585.\n",
      "Step: 955000. Mean Reward: -7.830754714641475. Std of Reward: 17.282879723099033.\n",
      "Step: 960000. Mean Reward: -8.142941172215659. Std of Reward: 17.018524999160505.\n",
      "Saved Model\n",
      "Step: 965000. Mean Reward: -8.598888911088851. Std of Reward: 15.892268922630937.\n",
      "Step: 970000. Mean Reward: -5.666590902272699. Std of Reward: 9.245894889871733.\n",
      "Step: 975000. Mean Reward: -5.27619048025395. Std of Reward: 13.200918255331654.\n",
      "Step: 980000. Mean Reward: -6.136399978999982. Std of Reward: 9.24890187446087.\n",
      "Saved Model\n",
      "Step: 985000. Mean Reward: -5.250000027898714. Std of Reward: 19.318217988057427.\n",
      "Step: 990000. Mean Reward: -3.8719512146707262. Std of Reward: 8.594433878052655.\n",
      "Step: 995000. Mean Reward: -4.847777776277764. Std of Reward: 7.547938807837525.\n",
      "Step: 1000000. Mean Reward: -5.756666663933321. Std of Reward: 9.807939188859581.\n",
      "Saved Model\n",
      "Step: 1005000. Mean Reward: -3.9430645051128845. Std of Reward: 6.590080170865029.\n",
      "Step: 1010000. Mean Reward: -6.694642851928547. Std of Reward: 15.143308628798719.\n",
      "Step: 1015000. Mean Reward: -4.185797098884049. Std of Reward: 6.012483488502454.\n",
      "Step: 1020000. Mean Reward: -4.407073165951211. Std of Reward: 11.848034360205792.\n",
      "Saved Model\n",
      "Step: 1025000. Mean Reward: -4.823749981972208. Std of Reward: 13.249928929374885.\n",
      "Step: 1030000. Mean Reward: -3.338082189808208. Std of Reward: 6.849497463320135.\n",
      "Step: 1035000. Mean Reward: -3.853529410838222. Std of Reward: 7.164156852445476.\n",
      "Step: 1040000. Mean Reward: -7.363461537211498. Std of Reward: 16.703995248079423.\n",
      "Saved Model\n",
      "Step: 1045000. Mean Reward: -2.711616162161614. Std of Reward: 6.6315014499167235.\n",
      "Step: 1050000. Mean Reward: -3.729014079366186. Std of Reward: 6.3981962995008415.\n",
      "Step: 1055000. Mean Reward: -5.077974706708855. Std of Reward: 11.405756844934317.\n",
      "Step: 1060000. Mean Reward: -4.748275861655152. Std of Reward: 8.346126530362898.\n",
      "Saved Model\n",
      "Step: 1065000. Mean Reward: -3.8243939386666552. Std of Reward: 7.141787427892553.\n",
      "Step: 1070000. Mean Reward: -4.121212170393928. Std of Reward: 13.670855026003037.\n",
      "Step: 1075000. Mean Reward: -3.4702666649866614. Std of Reward: 5.380590544152142.\n",
      "Step: 1080000. Mean Reward: -5.836825394206337. Std of Reward: 13.94278977676681.\n",
      "Saved Model\n",
      "Step: 1085000. Mean Reward: -3.4366666626881637. Std of Reward: 11.21910326652526.\n",
      "Step: 1090000. Mean Reward: -6.463012225530121. Std of Reward: 27.346376905009194.\n",
      "Step: 1095000. Mean Reward: -6.43603447105169. Std of Reward: 16.173215503366603.\n",
      "Step: 1100000. Mean Reward: -5.243108119472964. Std of Reward: 13.271145786996891.\n",
      "Saved Model\n",
      "Step: 1105000. Mean Reward: -4.387538460246139. Std of Reward: 11.012913403722914.\n",
      "Step: 1110000. Mean Reward: -8.715454630254547. Std of Reward: 29.373655954383995.\n",
      "Step: 1115000. Mean Reward: -2.9163541619270816. Std of Reward: 5.065839458112197.\n",
      "Step: 1120000. Mean Reward: -2.871078430078427. Std of Reward: 10.419421336683058.\n",
      "Saved Model\n",
      "Step: 1125000. Mean Reward: -2.008761058407076. Std of Reward: 3.9064285783496184.\n",
      "Step: 1130000. Mean Reward: -6.325416738930526. Std of Reward: 25.657167466818432.\n",
      "Step: 1135000. Mean Reward: -3.9270212838829672. Std of Reward: 12.872718509295526.\n",
      "Step: 1140000. Mean Reward: -5.799032254629047. Std of Reward: 17.517424478329534.\n",
      "Saved Model\n",
      "Step: 1145000. Mean Reward: -3.7998529379117554. Std of Reward: 5.858121183180747.\n",
      "Step: 1150000. Mean Reward: -4.747659571723386. Std of Reward: 7.9655209701111875.\n",
      "Step: 1155000. Mean Reward: -5.378823626811739. Std of Reward: 26.80203580182963.\n",
      "Step: 1160000. Mean Reward: -6.529342247026281. Std of Reward: 32.04407516863424.\n",
      "Saved Model\n",
      "Step: 1165000. Mean Reward: -7.07770836237497. Std of Reward: 16.116099559759725.\n",
      "Step: 1170000. Mean Reward: -7.2434615702115135. Std of Reward: 19.526321645085098.\n",
      "Step: 1175000. Mean Reward: -6.256271185830508. Std of Reward: 15.80466793309755.\n",
      "Step: 1180000. Mean Reward: -4.829534878093. Std of Reward: 7.089284395034948.\n",
      "Saved Model\n",
      "Step: 1185000. Mean Reward: -3.7971666650166567. Std of Reward: 5.052996171546839.\n",
      "Step: 1190000. Mean Reward: -4.319846151753834. Std of Reward: 11.297642026498798.\n",
      "Step: 1195000. Mean Reward: -4.419122800368406. Std of Reward: 6.944010990235506.\n",
      "Step: 1200000. Mean Reward: -3.5149999868666524. Std of Reward: 6.494127194999329.\n",
      "Saved Model\n",
      "Step: 1205000. Mean Reward: -5.098431371960766. Std of Reward: 8.649468162793339.\n",
      "Step: 1210000. Mean Reward: -3.9020338940169372. Std of Reward: 5.198020083227961.\n",
      "Step: 1215000. Mean Reward: -3.1838823505999967. Std of Reward: 6.128391419687538.\n",
      "Step: 1220000. Mean Reward: -3.174029849985065. Std of Reward: 5.6181459897147175.\n",
      "Saved Model\n",
      "Step: 1225000. Mean Reward: -6.187258081338691. Std of Reward: 20.65345213699611.\n",
      "Step: 1230000. Mean Reward: -7.987631570184175. Std of Reward: 15.331547528327635.\n",
      "Step: 1235000. Mean Reward: -3.6462711862881343. Std of Reward: 5.042135308555749.\n",
      "Step: 1240000. Mean Reward: -3.6454285902142742. Std of Reward: 8.181864313742764.\n",
      "Saved Model\n",
      "Step: 1245000. Mean Reward: -6.387962962907388. Std of Reward: 14.652260649611302.\n",
      "Step: 1250000. Mean Reward: -10.914680956893577. Std of Reward: 30.787886374825955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1255000. Mean Reward: -6.323968329952356. Std of Reward: 23.098127209779694.\n",
      "Step: 1260000. Mean Reward: -4.866666666666648. Std of Reward: 7.126531336413832.\n",
      "Saved Model\n",
      "Step: 1265000. Mean Reward: -6.115789471315785. Std of Reward: 20.427696622659862.\n",
      "Step: 1270000. Mean Reward: -5.754210521982431. Std of Reward: 14.882311288963718.\n",
      "Step: 1275000. Mean Reward: -4.227678571374982. Std of Reward: 7.220113768204011.\n",
      "Step: 1280000. Mean Reward: -1.9357999977599982. Std of Reward: 3.887860637111413.\n",
      "Saved Model\n",
      "Step: 1285000. Mean Reward: -8.558125046499976. Std of Reward: 18.038483928962318.\n",
      "Step: 1290000. Mean Reward: -3.9496610162881356. Std of Reward: 18.415532957958487.\n",
      "Step: 1295000. Mean Reward: -10.764999980156222. Std of Reward: 18.36764087490553.\n",
      "Step: 1300000. Mean Reward: -8.151836730673468. Std of Reward: 24.46569824274204.\n",
      "Saved Model\n",
      "Step: 1305000. Mean Reward: -10.065111104888889. Std of Reward: 29.24590528812289.\n",
      "Step: 1310000. Mean Reward: -15.913437491656257. Std of Reward: 33.50902365720559.\n",
      "Step: 1315000. Mean Reward: -6.731509432433955. Std of Reward: 13.471827543002938.\n",
      "Step: 1320000. Mean Reward: -8.262272718931793. Std of Reward: 18.486939231976915.\n",
      "Saved Model\n",
      "Step: 1325000. Mean Reward: -12.321212081484866. Std of Reward: 29.88216074426803.\n",
      "Step: 1330000. Mean Reward: -9.558837338441796. Std of Reward: 33.51705202562174.\n",
      "Step: 1335000. Mean Reward: -5.122363636145444. Std of Reward: 10.595203539843224.\n",
      "Step: 1340000. Mean Reward: -3.487457625389821. Std of Reward: 5.528206745014754.\n",
      "Saved Model\n",
      "Step: 1345000. Mean Reward: -6.611233007835586. Std of Reward: 31.030716047060334.\n",
      "Step: 1350000. Mean Reward: -3.8809090893181666. Std of Reward: 11.973814577898759.\n",
      "Step: 1355000. Mean Reward: -4.698541665166641. Std of Reward: 8.409325426004063.\n",
      "Step: 1360000. Mean Reward: -6.596037723698093. Std of Reward: 15.534304134008035.\n",
      "Saved Model\n",
      "Step: 1365000. Mean Reward: -5.591739116478237. Std of Reward: 9.415708016076639.\n",
      "Step: 1370000. Mean Reward: -10.71547192658486. Std of Reward: 38.09913874082933.\n",
      "Step: 1375000. Mean Reward: -3.2844705785529325. Std of Reward: 6.396748342615314.\n",
      "Step: 1380000. Mean Reward: -3.9575999974399836. Std of Reward: 15.150132746924854.\n",
      "Saved Model\n",
      "Step: 1385000. Mean Reward: -7.022253491168998. Std of Reward: 19.585658073563977.\n",
      "Step: 1390000. Mean Reward: -4.2291666597737985. Std of Reward: 12.020123617691844.\n",
      "Step: 1395000. Mean Reward: -4.475438596175438. Std of Reward: 8.372320114890016.\n",
      "Step: 1400000. Mean Reward: -3.938382351705865. Std of Reward: 10.845231618682462.\n",
      "Saved Model\n",
      "Step: 1405000. Mean Reward: -6.981136353136335. Std of Reward: 10.498125613252036.\n",
      "Step: 1410000. Mean Reward: -11.550434762086947. Std of Reward: 29.90873537951646.\n",
      "Step: 1415000. Mean Reward: -4.306447362736827. Std of Reward: 11.823292878641244.\n",
      "Step: 1420000. Mean Reward: -6.761698104264151. Std of Reward: 15.65225750381479.\n",
      "Saved Model\n",
      "Step: 1425000. Mean Reward: -6.2427941870294. Std of Reward: 18.863582429909478.\n",
      "Step: 1430000. Mean Reward: -6.6133333317777785. Std of Reward: 12.197473873650262.\n",
      "Step: 1435000. Mean Reward: -3.6777499938249902. Std of Reward: 10.538678633382291.\n",
      "Step: 1440000. Mean Reward: -5.955909128386347. Std of Reward: 10.230027376596293.\n",
      "Saved Model\n",
      "Step: 1445000. Mean Reward: -8.075294114725468. Std of Reward: 17.41052581796989.\n",
      "Step: 1450000. Mean Reward: -3.8424999936346085. Std of Reward: 6.144987595052863.\n",
      "Step: 1455000. Mean Reward: -3.7094949372828285. Std of Reward: 10.133928431891599.\n",
      "Step: 1460000. Mean Reward: -4.647777766759243. Std of Reward: 8.342284669247856.\n",
      "Saved Model\n",
      "Step: 1465000. Mean Reward: -3.9506153813999827. Std of Reward: 6.99416435223795.\n",
      "Step: 1470000. Mean Reward: -5.691851850092571. Std of Reward: 13.2973804263336.\n",
      "Step: 1475000. Mean Reward: -4.185633792408439. Std of Reward: 6.8668078236969325.\n",
      "Step: 1480000. Mean Reward: -3.1978666660666564. Std of Reward: 8.193940410245908.\n",
      "Saved Model\n",
      "Step: 1485000. Mean Reward: -4.393098591464776. Std of Reward: 10.818921165576992.\n",
      "Step: 1490000. Mean Reward: -4.7649019604901826. Std of Reward: 7.903789949995392.\n",
      "Step: 1495000. Mean Reward: -3.6721874865624913. Std of Reward: 6.377001968563997.\n",
      "Step: 1500000. Mean Reward: -5.014920633174604. Std of Reward: 10.267216106903133.\n",
      "Saved Model\n",
      "Step: 1505000. Mean Reward: -7.261818171590898. Std of Reward: 15.38393572711195.\n",
      "Step: 1510000. Mean Reward: -4.197681155376815. Std of Reward: 7.585053023251431.\n",
      "Step: 1515000. Mean Reward: -3.5818518380370334. Std of Reward: 8.527211572050899.\n",
      "Step: 1520000. Mean Reward: -8.009534900790674. Std of Reward: 14.07705136875373.\n",
      "Saved Model\n",
      "Step: 1525000. Mean Reward: -4.4989473216842. Std of Reward: 8.860129805801877.\n",
      "Step: 1530000. Mean Reward: -3.406052629565788. Std of Reward: 7.393577952235508.\n",
      "Step: 1535000. Mean Reward: -6.171836733102044. Std of Reward: 13.722505375710238.\n",
      "Step: 1540000. Mean Reward: -3.911296295740728. Std of Reward: 6.974167691471403.\n",
      "Saved Model\n",
      "Step: 1545000. Mean Reward: -3.4174999997999858. Std of Reward: 6.59276765985812.\n",
      "Step: 1550000. Mean Reward: -3.713432831373121. Std of Reward: 7.110549140432277.\n",
      "Step: 1555000. Mean Reward: -5.739999998545428. Std of Reward: 11.791696153927857.\n",
      "Step: 1560000. Mean Reward: -4.780204077326509. Std of Reward: 8.531459786051752.\n",
      "Saved Model\n",
      "Step: 1565000. Mean Reward: -2.8397297294864754. Std of Reward: 6.273826577712845.\n",
      "Step: 1570000. Mean Reward: -4.35599999879999. Std of Reward: 7.639969443302593.\n",
      "Step: 1575000. Mean Reward: -3.6182258028064433. Std of Reward: 7.61714630315491.\n",
      "Step: 1580000. Mean Reward: -5.737727292772711. Std of Reward: 10.474254808771247.\n",
      "Saved Model\n",
      "Step: 1585000. Mean Reward: -5.109821420214268. Std of Reward: 10.83133442020525.\n",
      "Step: 1590000. Mean Reward: -5.066944457319439. Std of Reward: 11.768900655674885.\n",
      "Step: 1595000. Mean Reward: -4.839107145624994. Std of Reward: 8.552244126083506.\n",
      "Step: 1600000. Mean Reward: -7.681714285199954. Std of Reward: 14.013629791252407.\n",
      "Saved Model\n",
      "Step: 1605000. Mean Reward: -3.9234545441817965. Std of Reward: 7.9413486875848385.\n",
      "Step: 1610000. Mean Reward: -3.4318965433620536. Std of Reward: 6.430399633075203.\n",
      "Step: 1615000. Mean Reward: -7.730303029575726. Std of Reward: 10.116396976600987.\n",
      "Step: 1620000. Mean Reward: -3.880999965416651. Std of Reward: 8.912781964889367.\n",
      "Saved Model\n",
      "Step: 1625000. Mean Reward: -3.7616901296197045. Std of Reward: 7.327581873081.\n",
      "Step: 1630000. Mean Reward: -2.8727710830120468. Std of Reward: 6.0282574185289866.\n",
      "Step: 1635000. Mean Reward: -4.014385964456123. Std of Reward: 8.001133256947732.\n",
      "Step: 1640000. Mean Reward: -3.699090908618174. Std of Reward: 6.659505106497298.\n",
      "Saved Model\n",
      "Step: 1645000. Mean Reward: -3.8572413786551643. Std of Reward: 8.114966333800467.\n",
      "Step: 1650000. Mean Reward: -3.360476202154755. Std of Reward: 7.893770942316996.\n",
      "Step: 1655000. Mean Reward: -3.4175342458904003. Std of Reward: 6.476138664863479.\n",
      "Step: 1660000. Mean Reward: -2.182149528869152. Std of Reward: 5.209263498280238.\n",
      "Saved Model\n",
      "Step: 1665000. Mean Reward: -3.4378461527230675. Std of Reward: 6.120588330896198.\n",
      "Step: 1670000. Mean Reward: -3.2382666661199924. Std of Reward: 5.385104238198448.\n",
      "Step: 1675000. Mean Reward: -5.30355262898684. Std of Reward: 19.88462317220602.\n",
      "Step: 1680000. Mean Reward: -2.627865164404489. Std of Reward: 5.479025883960249.\n",
      "Saved Model\n",
      "Step: 1685000. Mean Reward: -3.8312857109999876. Std of Reward: 8.971965849510092.\n",
      "Step: 1690000. Mean Reward: -3.4230379741518937. Std of Reward: 5.975469973671584.\n",
      "Step: 1695000. Mean Reward: -3.3469620199746855. Std of Reward: 6.509597264901805.\n",
      "Step: 1700000. Mean Reward: -5.251136363227249. Std of Reward: 8.372762989413218.\n",
      "Saved Model\n",
      "Step: 1705000. Mean Reward: -2.78831460122471. Std of Reward: 6.34363667126049.\n",
      "Step: 1710000. Mean Reward: -2.4234736828315735. Std of Reward: 5.271095515456989.\n",
      "Step: 1715000. Mean Reward: -2.9398611106110994. Std of Reward: 5.903808915034983.\n",
      "Step: 1720000. Mean Reward: -3.0875294097764634. Std of Reward: 7.774343914794562.\n",
      "Saved Model\n",
      "Step: 1725000. Mean Reward: -2.7815624968437405. Std of Reward: 6.043169753440487.\n",
      "Step: 1730000. Mean Reward: -3.5144594570135. Std of Reward: 6.73382429021107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1735000. Mean Reward: -2.9303896091558346. Std of Reward: 5.871970939077308.\n",
      "Step: 1740000. Mean Reward: -2.355584410883109. Std of Reward: 5.743581503083017.\n",
      "Saved Model\n",
      "Step: 1745000. Mean Reward: -4.243103440344807. Std of Reward: 8.274959358005448.\n",
      "Step: 1750000. Mean Reward: -2.2322137446259487. Std of Reward: 7.00605862536802.\n",
      "Step: 1755000. Mean Reward: -4.954464284678564. Std of Reward: 10.811526739179696.\n",
      "Step: 1760000. Mean Reward: -2.419263153336837. Std of Reward: 4.4244807545325235.\n",
      "Saved Model\n",
      "Step: 1765000. Mean Reward: -3.765820882716409. Std of Reward: 10.51452613738248.\n",
      "Step: 1770000. Mean Reward: -4.00298245529823. Std of Reward: 12.319018810182117.\n",
      "Step: 1775000. Mean Reward: -3.070649346999984. Std of Reward: 7.426141668888231.\n",
      "Step: 1780000. Mean Reward: -4.567536217565203. Std of Reward: 12.900041270875212.\n",
      "Saved Model\n",
      "Step: 1785000. Mean Reward: -3.714374999812483. Std of Reward: 6.9165417378166945.\n",
      "Step: 1790000. Mean Reward: -2.396629193842689. Std of Reward: 5.689966625220452.\n",
      "Step: 1795000. Mean Reward: -2.5129629394444373. Std of Reward: 6.35818207275972.\n",
      "Step: 1800000. Mean Reward: -4.01016128546772. Std of Reward: 8.427607566348438.\n",
      "Saved Model\n",
      "Step: 1805000. Mean Reward: -2.503488369290688. Std of Reward: 5.492005344945823.\n",
      "Step: 1810000. Mean Reward: -3.565492954380273. Std of Reward: 7.079546970476055.\n",
      "Step: 1815000. Mean Reward: -6.683888886333314. Std of Reward: 15.764501427777692.\n",
      "Step: 1820000. Mean Reward: -1.9630158636904695. Std of Reward: 4.866379506592572.\n",
      "Saved Model\n",
      "Step: 1825000. Mean Reward: -7.52627914639533. Std of Reward: 18.364272001475538.\n",
      "Step: 1830000. Mean Reward: -3.9137096750645055. Std of Reward: 6.968550604576904.\n",
      "Step: 1835000. Mean Reward: -2.821851851148132. Std of Reward: 6.964342002977307.\n",
      "Step: 1840000. Mean Reward: -2.8973529385882344. Std of Reward: 5.64130137720002.\n",
      "Saved Model\n",
      "Step: 1845000. Mean Reward: -3.013432834820885. Std of Reward: 6.486322820539116.\n",
      "Step: 1850000. Mean Reward: -2.044799996149995. Std of Reward: 5.171969734193074.\n",
      "Step: 1855000. Mean Reward: -3.9775806380806262. Std of Reward: 7.642570427931257.\n",
      "Step: 1860000. Mean Reward: -2.6022549138235256. Std of Reward: 6.736285192040833.\n",
      "Saved Model\n",
      "Step: 1865000. Mean Reward: -2.9098630118082096. Std of Reward: 5.357460166868298.\n",
      "Step: 1870000. Mean Reward: -2.620153845692303. Std of Reward: 5.114534189782261.\n",
      "Step: 1875000. Mean Reward: -4.6380769144615215. Std of Reward: 10.686908959529564.\n",
      "Step: 1880000. Mean Reward: -2.3976595722446743. Std of Reward: 4.755458323093007.\n",
      "Saved Model\n",
      "Step: 1885000. Mean Reward: -4.898360654967193. Std of Reward: 11.29049740907231.\n",
      "Step: 1890000. Mean Reward: -2.3422619038214285. Std of Reward: 5.327533010680747.\n",
      "Step: 1895000. Mean Reward: -2.2860416630729126. Std of Reward: 4.640583761439155.\n",
      "Step: 1900000. Mean Reward: -2.409999996968081. Std of Reward: 4.523888130839097.\n",
      "Saved Model\n",
      "Step: 1905000. Mean Reward: -2.4051375989908186. Std of Reward: 5.8866425418897315.\n",
      "Step: 1910000. Mean Reward: -2.3268478248586897. Std of Reward: 4.948152252310841.\n",
      "Step: 1915000. Mean Reward: -2.3676842085368346. Std of Reward: 5.318509774787247.\n",
      "Step: 1920000. Mean Reward: -2.558351647252742. Std of Reward: 5.141718459169488.\n",
      "Saved Model\n",
      "Step: 1925000. Mean Reward: -2.0188775504489773. Std of Reward: 3.6578701506931424.\n",
      "Step: 1930000. Mean Reward: -3.7184090888181704. Std of Reward: 9.145442095008967.\n",
      "Step: 1935000. Mean Reward: -4.019333332733326. Std of Reward: 8.912617024577733.\n",
      "Step: 1940000. Mean Reward: -1.5015686270980342. Std of Reward: 4.026779900089857.\n",
      "Saved Model\n",
      "Step: 1945000. Mean Reward: -2.54791666513888. Std of Reward: 5.212844962800386.\n",
      "Step: 1950000. Mean Reward: -3.5236781567126307. Std of Reward: 10.461685663502168.\n",
      "Step: 1955000. Mean Reward: -2.3738947341263152. Std of Reward: 5.656353910244302.\n",
      "Step: 1960000. Mean Reward: -3.6359999971692263. Std of Reward: 5.698758785074789.\n",
      "Saved Model\n",
      "Step: 1965000. Mean Reward: -3.3521874998124948. Std of Reward: 4.888249453015311.\n",
      "Step: 1970000. Mean Reward: -3.720547943452044. Std of Reward: 7.494773317976196.\n",
      "Step: 1975000. Mean Reward: -2.1281739090347775. Std of Reward: 4.790229650692853.\n",
      "Step: 1980000. Mean Reward: -3.007124996549989. Std of Reward: 6.215832243408176.\n",
      "Saved Model\n",
      "Step: 1985000. Mean Reward: -3.0293939369242326. Std of Reward: 4.82642878167284.\n",
      "Step: 1990000. Mean Reward: -1.6824817514306545. Std of Reward: 3.9570592528029236.\n",
      "Step: 1995000. Mean Reward: -2.513603595558552. Std of Reward: 8.375173814401776.\n",
      "Step: 2000000. Mean Reward: -2.9549999993999916. Std of Reward: 6.4966740394087825.\n",
      "Saved Model\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons18/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons18/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons18/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons18/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
