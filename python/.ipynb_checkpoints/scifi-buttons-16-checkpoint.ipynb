{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esmu/miniconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 2e6 # Set maximum number of steps to run environment.\n",
    "run_path = \"scifibuttons16\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 5000 # Frequency at which to save training statistics.\n",
    "save_freq = 20000 # Frequency at which to save model.\n",
    "env_name = \"scifibuttons15\" # Name of the training environment file.\n",
    "curriculum_file = 'curricula/lessons16.json'\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 1e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 2 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 2048 #2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 128 # Number of units in hidden layer.\n",
    "batch_size = 64 #64 # How many experiences per gradient descent update step.\n",
    "normalize = True\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\tlessonNr -> 1.0\n",
      "Unity brain name: Brain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 30\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 5\n",
      "        Memory space size (per agent): 3\n",
      "        Action descriptions: , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000. Mean Reward: -1.429907814034562. Std of Reward: 2.2783513200653713.\n",
      "Step: 10000. Mean Reward: -1.4573499768395002. Std of Reward: 2.5851967808938725.\n",
      "Step: 15000. Mean Reward: -1.4307762333634702. Std of Reward: 2.4200931561996515.\n",
      "Step: 20000. Mean Reward: -0.8074131091065637. Std of Reward: 1.823498225918017.\n",
      "Saved Model\n",
      "Step: 25000. Mean Reward: -0.7531938993000001. Std of Reward: 1.886540787695386.\n",
      "Step: 30000. Mean Reward: -0.6337809023346289. Std of Reward: 1.8527512130584616.\n",
      "Step: 35000. Mean Reward: -0.6239483229468638. Std of Reward: 1.8238530918992522.\n",
      "Step: 40000. Mean Reward: -0.5594932275493245. Std of Reward: 1.5771615545141475.\n",
      "Saved Model\n",
      "Step: 45000. Mean Reward: -0.35609522492126994. Std of Reward: 1.6768438710518832.\n",
      "Step: 50000. Mean Reward: -0.4300651334791532. Std of Reward: 1.5933816613694691.\n",
      "Step: 55000. Mean Reward: -0.2370461407723079. Std of Reward: 1.4170363006942222.\n",
      "Step: 60000. Mean Reward: -0.20576801234482767. Std of Reward: 1.3487153809310262.\n",
      "Saved Model\n",
      "Step: 65000. Mean Reward: -0.2436592903302841. Std of Reward: 1.4593141989678124.\n",
      "Step: 70000. Mean Reward: -0.13279659900028257. Std of Reward: 1.253150074170696.\n",
      "Step: 75000. Mean Reward: -0.1322375577618785. Std of Reward: 1.1636042353521072.\n",
      "Step: 80000. Mean Reward: 0.014346678590133275. Std of Reward: 1.0359603777634006.\n",
      "Saved Model\n",
      "Step: 85000. Mean Reward: -0.034109937137172856. Std of Reward: 1.0882540949996629.\n",
      "Step: 90000. Mean Reward: 0.01677501000699993. Std of Reward: 1.1135386589340626.\n",
      "Step: 95000. Mean Reward: 0.14232143731071425. Std of Reward: 0.9748342180959357.\n",
      "Step: 100000. Mean Reward: 0.19677130899372192. Std of Reward: 0.9267767457351044.\n",
      "Saved Model\n",
      "Step: 105000. Mean Reward: 0.11220624521966423. Std of Reward: 1.0691882315315264.\n",
      "Step: 110000. Mean Reward: 0.22735730205665958. Std of Reward: 0.9560945015586592.\n",
      "Step: 115000. Mean Reward: 0.11068376919786321. Std of Reward: 1.059036593142645.\n",
      "Step: 120000. Mean Reward: 0.2793824779858565. Std of Reward: 0.9795044145158694.\n",
      "Saved Model\n",
      "Step: 125000. Mean Reward: 0.2729981101612903. Std of Reward: 0.887155511257798.\n",
      "Step: 130000. Mean Reward: 0.34272887978327465. Std of Reward: 0.8689809794431445.\n",
      "Step: 135000. Mean Reward: 0.3540720788082882. Std of Reward: 0.8969568145982928.\n",
      "Step: 140000. Mean Reward: 0.39336079669785834. Std of Reward: 0.8565294755161942.\n",
      "Saved Model\n",
      "Step: 145000. Mean Reward: 0.38242812089377. Std of Reward: 0.883367169271625.\n",
      "Step: 150000. Mean Reward: 0.49025035252002774. Std of Reward: 0.8042082954151557.\n",
      "Step: 155000. Mean Reward: 0.4741289486144033. Std of Reward: 0.8268794301306833.\n",
      "Step: 160000. Mean Reward: 0.5032832123848371. Std of Reward: 0.7986530005163016.\n",
      "Saved Model\n",
      "Step: 165000. Mean Reward: 0.5457482224777909. Std of Reward: 0.7655789574171189.\n",
      "Step: 170000. Mean Reward: 0.6027881485904502. Std of Reward: 0.7361648321620323.\n",
      "Step: 175000. Mean Reward: 0.5873661705316916. Std of Reward: 0.754809363703108.\n",
      "Step: 180000. Mean Reward: 0.6706256340362259. Std of Reward: 0.6636256503480643.\n",
      "Saved Model\n",
      "Step: 185000. Mean Reward: 0.6898185323844316. Std of Reward: 0.6643528613856208.\n",
      "Step: 190000. Mean Reward: 0.7388930611930581. Std of Reward: 0.5982672719184653.\n",
      "Step: 195000. Mean Reward: 0.7731250028308979. Std of Reward: 0.5608885422684454.\n",
      "Step: 200000. Mean Reward: 0.7773031852535176. Std of Reward: 0.5623019786569488.\n",
      "Saved Model\n",
      "Step: 205000. Mean Reward: 0.8067734016313628. Std of Reward: 0.5266290074165905.\n",
      "Step: 210000. Mean Reward: 0.8384289104468186. Std of Reward: 0.4642842081711549.\n",
      "Step: 215000. Mean Reward: 0.8427315199302723. Std of Reward: 0.45392118890220146.\n",
      "Step: 220000. Mean Reward: 0.8672795802718161. Std of Reward: 0.4180826796727049.\n",
      "Saved Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 1 : \tlessonNr -> 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 225000. Mean Reward: 0.8835802490875817. Std of Reward: 0.38149121626680543.\n",
      "Step: 230000. Mean Reward: -0.8009045180097991. Std of Reward: 5.132223593189805.\n",
      "Step: 235000. Mean Reward: -0.6253527951357666. Std of Reward: 2.3734909648697813.\n",
      "Step: 240000. Mean Reward: -0.9672440848220476. Std of Reward: 6.201726661538756.\n",
      "Saved Model\n",
      "Step: 245000. Mean Reward: -0.36266958236936553. Std of Reward: 1.9083617251361946.\n",
      "Step: 250000. Mean Reward: -0.19493307625697903. Std of Reward: 1.9127794292153073.\n",
      "Step: 255000. Mean Reward: 0.040231318155871845. Std of Reward: 1.3809645519408782.\n",
      "Step: 260000. Mean Reward: 0.027756850434931465. Std of Reward: 1.366544458929362.\n",
      "Saved Model\n",
      "Step: 265000. Mean Reward: 0.15931438212909696. Std of Reward: 1.158232141151821.\n",
      "Step: 270000. Mean Reward: 0.28744881929921257. Std of Reward: 0.8838848263585535.\n",
      "Step: 275000. Mean Reward: 0.37162202403035716. Std of Reward: 0.8248363216558322.\n",
      "Step: 280000. Mean Reward: 0.30258064535659823. Std of Reward: 0.909498957760801.\n",
      "Saved Model\n",
      "Step: 285000. Mean Reward: 0.37612625596355814. Std of Reward: 1.019969006829023.\n",
      "Step: 290000. Mean Reward: 0.28030726311675974. Std of Reward: 1.1311959911144387.\n",
      "Step: 295000. Mean Reward: 0.388381742949101. Std of Reward: 0.8636464608205505.\n",
      "Step: 300000. Mean Reward: 0.39244623674919354. Std of Reward: 0.9217195152455157.\n",
      "Saved Model\n",
      "Step: 305000. Mean Reward: 0.4208222813246684. Std of Reward: 0.7835027198063707.\n",
      "Step: 310000. Mean Reward: 0.4100933335586667. Std of Reward: 0.8531526572183146.\n",
      "Step: 315000. Mean Reward: 0.4032594526915254. Std of Reward: 0.9639772910641272.\n",
      "Step: 320000. Mean Reward: 0.4425968994488372. Std of Reward: 0.7666042105136205.\n",
      "Saved Model\n",
      "Step: 325000. Mean Reward: 0.474760101260101. Std of Reward: 0.7848699901624342.\n",
      "Step: 330000. Mean Reward: 0.43836363666363637. Std of Reward: 0.801087684181297.\n",
      "Step: 335000. Mean Reward: 0.4463694270150318. Std of Reward: 0.7515590192163905.\n",
      "Step: 340000. Mean Reward: 0.4930992739808716. Std of Reward: 0.7871078838314015.\n",
      "Saved Model\n",
      "Step: 345000. Mean Reward: 0.4666545458756363. Std of Reward: 0.7886815747506406.\n",
      "Step: 350000. Mean Reward: 0.5060381865326968. Std of Reward: 0.6797430782466819.\n",
      "Step: 355000. Mean Reward: 0.5125232563746511. Std of Reward: 0.7316796736751664.\n",
      "Step: 360000. Mean Reward: 0.5228715089890503. Std of Reward: 0.7401435166087592.\n",
      "Saved Model\n",
      "Step: 365000. Mean Reward: 0.5080289539565701. Std of Reward: 0.7230403294446992.\n",
      "Step: 370000. Mean Reward: 0.5089740830516198. Std of Reward: 0.7681305503026522.\n",
      "Step: 375000. Mean Reward: 0.5645717354117774. Std of Reward: 0.6607869386851014.\n",
      "Step: 380000. Mean Reward: 0.5024416145571126. Std of Reward: 0.7786703955492176.\n",
      "Saved Model\n",
      "Step: 385000. Mean Reward: 0.6079093729342945. Std of Reward: 0.6580039229779823.\n",
      "Step: 390000. Mean Reward: 0.5940691770754832. Std of Reward: 0.645597914748413.\n",
      "Step: 395000. Mean Reward: 0.5648746250387161. Std of Reward: 0.6999060763550979.\n",
      "Step: 400000. Mean Reward: 0.5899494960161615. Std of Reward: 0.6667052247360338.\n",
      "Saved Model\n",
      "Step: 405000. Mean Reward: 0.6447895803378758. Std of Reward: 0.5959527044410554.\n",
      "Step: 410000. Mean Reward: 0.6675375386334333. Std of Reward: 0.5338214199560993.\n",
      "Step: 415000. Mean Reward: 0.633262840887009. Std of Reward: 0.5836988604382012.\n",
      "Step: 420000. Mean Reward: 0.662095333750149. Std of Reward: 0.5415385779425861.\n",
      "Saved Model\n",
      "Step: 425000. Mean Reward: 0.6574085075897133. Std of Reward: 0.5589551605788804.\n",
      "Step: 430000. Mean Reward: 0.6918537084248497. Std of Reward: 0.4699154310333467.\n",
      "Step: 435000. Mean Reward: 0.67788594013294. Std of Reward: 0.5172489396941412.\n",
      "Step: 440000. Mean Reward: 0.6880000011449756. Std of Reward: 0.5122868868246522.\n",
      "Saved Model\n",
      "Step: 445000. Mean Reward: 0.6024284314860809. Std of Reward: 0.6596138650742207.\n",
      "Step: 450000. Mean Reward: 0.5699804697367188. Std of Reward: 0.6978061327777625.\n",
      "Step: 455000. Mean Reward: 0.6175557722089234. Std of Reward: 0.6315771226357403.\n",
      "Step: 460000. Mean Reward: 0.6612610848807882. Std of Reward: 0.555158155813817.\n",
      "Saved Model\n",
      "Step: 465000. Mean Reward: 0.6775934814722914. Std of Reward: 0.5525345248859947.\n",
      "Step: 470000. Mean Reward: 0.6484807702382691. Std of Reward: 0.5824310789457248.\n",
      "Step: 475000. Mean Reward: 0.6754738889197291. Std of Reward: 0.5533196969477429.\n",
      "Step: 480000. Mean Reward: 0.6770465348866097. Std of Reward: 0.5732678319813944.\n",
      "Saved Model\n",
      "Step: 485000. Mean Reward: 0.6318296235039691. Std of Reward: 0.6016880439813516.\n",
      "Step: 490000. Mean Reward: 0.6006933604171875. Std of Reward: 0.6304698215635904.\n",
      "Step: 495000. Mean Reward: 0.6181034493038314. Std of Reward: 0.62410966905727.\n",
      "Step: 500000. Mean Reward: 0.623891051581712. Std of Reward: 0.6060748215343353.\n",
      "Saved Model\n",
      "Step: 505000. Mean Reward: 0.6521278635370229. Std of Reward: 0.550104739829438.\n",
      "Step: 510000. Mean Reward: 0.650568721473744. Std of Reward: 0.5860248119293722.\n",
      "Step: 515000. Mean Reward: 0.655253589535311. Std of Reward: 0.5594500534149186.\n",
      "Step: 520000. Mean Reward: 0.6658157399666026. Std of Reward: 0.534127050167599.\n",
      "Saved Model\n",
      "Step: 525000. Mean Reward: 0.6833587796305344. Std of Reward: 0.5099674231802493.\n",
      "Step: 530000. Mean Reward: 0.6784084382362416. Std of Reward: 0.5064933670802978.\n",
      "Step: 535000. Mean Reward: 0.651674551674929. Std of Reward: 0.5785949582437684.\n",
      "Step: 540000. Mean Reward: 0.6560357826131826. Std of Reward: 0.5827157436528825.\n",
      "Saved Model\n",
      "Step: 545000. Mean Reward: 0.652971429703619. Std of Reward: 0.591283615787812.\n",
      "Step: 550000. Mean Reward: 0.6784753799022727. Std of Reward: 0.5338583881123402.\n",
      "Step: 555000. Mean Reward: 0.6727246935315042. Std of Reward: 0.5331427622525079.\n",
      "Step: 560000. Mean Reward: 0.6489543735657796. Std of Reward: 0.5413955795130583.\n",
      "Saved Model\n",
      "Step: 565000. Mean Reward: 0.7127137557442379. Std of Reward: 0.496243955848981.\n",
      "Step: 570000. Mean Reward: 0.7175929379895911. Std of Reward: 0.4765876094811076.\n",
      "Step: 575000. Mean Reward: 0.7116044786716418. Std of Reward: 0.4664999889935991.\n",
      "Step: 580000. Mean Reward: 0.7320670402301677. Std of Reward: 0.43558797337244404.\n",
      "Saved Model\n",
      "Step: 585000. Mean Reward: 0.7044297842262017. Std of Reward: 0.4577249612356845.\n",
      "Step: 590000. Mean Reward: 0.7059065431439253. Std of Reward: 0.47336839437093303.\n",
      "Step: 595000. Mean Reward: 0.7002539992030103. Std of Reward: 0.4975301483279829.\n",
      "Step: 600000. Mean Reward: 0.7338139546135813. Std of Reward: 0.43628747028446474.\n",
      "Saved Model\n",
      "Step: 605000. Mean Reward: 0.685455408940038. Std of Reward: 0.48889579733051236.\n",
      "Step: 610000. Mean Reward: 0.7107169822181132. Std of Reward: 0.46202819464560013.\n",
      "Step: 615000. Mean Reward: 0.6930300198067543. Std of Reward: 0.5002130069403143.\n",
      "Step: 620000. Mean Reward: 0.69035747985889. Std of Reward: 0.5090232515553538.\n",
      "Saved Model\n",
      "Step: 625000. Mean Reward: 0.6924394796472997. Std of Reward: 0.5180440665009332.\n",
      "Step: 630000. Mean Reward: 0.6766573566897579. Std of Reward: 0.5229374672445098.\n",
      "Step: 635000. Mean Reward: 0.6961106001448849. Std of Reward: 0.5236336949815982.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "Lesson changed. Now in Lesson 2 : \tlessonNr -> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 640000. Mean Reward: -7.359520956426392. Std of Reward: 27.765009699911037.\n",
      "Saved Model\n",
      "Step: 645000. Mean Reward: -7.461741571432628. Std of Reward: 26.909815001617567.\n",
      "Step: 650000. Mean Reward: -4.733589742226524. Std of Reward: 22.916374557704422.\n",
      "Step: 655000. Mean Reward: -1.674504949103966. Std of Reward: 9.845677693916736.\n",
      "Step: 660000. Mean Reward: -3.401612902082456. Std of Reward: 18.34186375965512.\n",
      "Saved Model\n",
      "Step: 665000. Mean Reward: -1.7258900513534092. Std of Reward: 11.15423834499032.\n",
      "Step: 670000. Mean Reward: -1.1767999983711122. Std of Reward: 5.499981652411533.\n",
      "Step: 675000. Mean Reward: -1.9483977891022193. Std of Reward: 13.040262731001796.\n",
      "Step: 680000. Mean Reward: -0.8192607792997953. Std of Reward: 3.824064010326834.\n",
      "Saved Model\n",
      "Step: 685000. Mean Reward: -1.305648146913892. Std of Reward: 7.4979157607791205.\n",
      "Step: 690000. Mean Reward: -0.5731128392898834. Std of Reward: 2.4984855389005736.\n",
      "Step: 695000. Mean Reward: -0.28018382287132354. Std of Reward: 1.695952024454447.\n",
      "Step: 700000. Mean Reward: -0.13689213846435105. Std of Reward: 1.3673407341942254.\n",
      "Saved Model\n",
      "Step: 705000. Mean Reward: -0.2749348224804469. Std of Reward: 1.9257491794651111.\n",
      "Step: 710000. Mean Reward: -0.15007259474773144. Std of Reward: 1.4077889333847475.\n",
      "Step: 715000. Mean Reward: -0.03967741872043017. Std of Reward: 1.0318683154400718.\n",
      "Step: 720000. Mean Reward: -0.033327401699288293. Std of Reward: 0.9720284365638435.\n",
      "Saved Model\n",
      "Step: 725000. Mean Reward: -0.07909747228700366. Std of Reward: 1.0557078365270696.\n",
      "Step: 730000. Mean Reward: -0.07742805702877703. Std of Reward: 1.050167013158404.\n",
      "Step: 735000. Mean Reward: -0.1458424903626374. Std of Reward: 1.3486005903103853.\n",
      "Step: 740000. Mean Reward: -0.09500897608797132. Std of Reward: 1.1524029396581759.\n",
      "Saved Model\n",
      "Step: 745000. Mean Reward: -0.10003533510247356. Std of Reward: 1.0733294170729137.\n",
      "Step: 750000. Mean Reward: -0.22971781215696652. Std of Reward: 1.3086132727191764.\n",
      "Step: 755000. Mean Reward: -0.16759226619507914. Std of Reward: 1.1689747345920787.\n",
      "Step: 760000. Mean Reward: -0.201431063790576. Std of Reward: 1.2379131684970828.\n",
      "Saved Model\n",
      "Step: 765000. Mean Reward: -0.21299307874740486. Std of Reward: 1.233464975874561.\n",
      "Step: 770000. Mean Reward: -0.2572635121993244. Std of Reward: 1.2532175906503749.\n",
      "Step: 775000. Mean Reward: -0.32821368814190327. Std of Reward: 1.3184521865363947.\n",
      "Step: 780000. Mean Reward: -0.3092294506318494. Std of Reward: 1.3931840861009128.\n",
      "Saved Model\n",
      "Step: 785000. Mean Reward: -0.28398009835986743. Std of Reward: 1.2657179244538566.\n",
      "Step: 790000. Mean Reward: -0.32104575042156874. Std of Reward: 1.2605470900660931.\n",
      "Step: 795000. Mean Reward: -0.3375163383496733. Std of Reward: 1.2719744447634462.\n",
      "Step: 800000. Mean Reward: -0.33263071766993474. Std of Reward: 1.2821712724570444.\n",
      "Saved Model\n",
      "Step: 805000. Mean Reward: -0.34263074374801905. Std of Reward: 1.283485887037405.\n",
      "Step: 810000. Mean Reward: -0.2979304884060032. Std of Reward: 1.242178044923796.\n",
      "Step: 815000. Mean Reward: -0.35193845999846163. Std of Reward: 1.2762344577526634.\n",
      "Step: 820000. Mean Reward: -0.3475037133105499. Std of Reward: 1.2218414737801535.\n",
      "Saved Model\n",
      "Step: 825000. Mean Reward: -0.2809214489607251. Std of Reward: 1.1399440379085957.\n",
      "Step: 830000. Mean Reward: -0.2967624802995462. Std of Reward: 1.1600725561377794.\n",
      "Step: 835000. Mean Reward: -0.26874806725193207. Std of Reward: 1.179344173767084.\n",
      "Step: 840000. Mean Reward: -0.23863436039647584. Std of Reward: 1.0349568705799161.\n",
      "Saved Model\n",
      "Step: 845000. Mean Reward: -0.2811494244497127. Std of Reward: 1.0598548742279694.\n",
      "Step: 850000. Mean Reward: -0.2863661964211268. Std of Reward: 1.096658704347149.\n",
      "Step: 855000. Mean Reward: -0.34379865621610745. Std of Reward: 1.0047187638014214.\n",
      "Step: 860000. Mean Reward: -0.3011748985220294. Std of Reward: 0.974677492030134.\n",
      "Saved Model\n",
      "Step: 865000. Mean Reward: -0.30780132337350996. Std of Reward: 0.9566995888146388.\n",
      "Step: 870000. Mean Reward: -0.2350133682981284. Std of Reward: 0.913000649304475.\n",
      "Step: 875000. Mean Reward: -0.24236459619022463. Std of Reward: 0.9141675627553616.\n",
      "Step: 880000. Mean Reward: -0.22787999919200003. Std of Reward: 0.8997999240503567.\n",
      "Saved Model\n",
      "Step: 885000. Mean Reward: -0.22339894940813654. Std of Reward: 0.8710075742093972.\n",
      "Step: 890000. Mean Reward: -0.2436923066935898. Std of Reward: 0.8779062834701858.\n",
      "Step: 895000. Mean Reward: -0.25092207661688315. Std of Reward: 0.8998384012564142.\n",
      "Step: 900000. Mean Reward: -0.25521126641357234. Std of Reward: 0.8893746737290554.\n",
      "Saved Model\n",
      "Step: 905000. Mean Reward: -0.21584196726554408. Std of Reward: 0.8646926974261256.\n",
      "Step: 910000. Mean Reward: -0.25287705795564014. Std of Reward: 0.8752124995451418.\n",
      "Step: 915000. Mean Reward: -0.19594033574578476. Std of Reward: 0.8480598086335847.\n",
      "Step: 920000. Mean Reward: -0.15020671643152458. Std of Reward: 0.8324115579762056.\n",
      "Saved Model\n",
      "Step: 925000. Mean Reward: -0.14390685313712812. Std of Reward: 0.8353716530251335.\n",
      "Step: 930000. Mean Reward: -0.06357797883748363. Std of Reward: 0.7995007728637409.\n",
      "Step: 935000. Mean Reward: -0.06981258074297192. Std of Reward: 0.8081959480830277.\n",
      "Step: 940000. Mean Reward: -0.042493400435356245. Std of Reward: 0.7982928598444945.\n",
      "Saved Model\n",
      "Step: 945000. Mean Reward: -0.07820209639632549. Std of Reward: 0.7942145123137025.\n",
      "Step: 950000. Mean Reward: 0.04765753841095887. Std of Reward: 0.7216961530474285.\n",
      "Step: 955000. Mean Reward: 0.031175679681081047. Std of Reward: 0.7469511719991356.\n",
      "Step: 960000. Mean Reward: 0.023644863846461927. Std of Reward: 0.7393682141129669.\n",
      "Saved Model\n",
      "Step: 965000. Mean Reward: 0.051447725254691656. Std of Reward: 0.7281607062298565.\n",
      "Step: 970000. Mean Reward: 0.02727873562615585. Std of Reward: 0.7709401666915434.\n",
      "Step: 975000. Mean Reward: 0.034325036699868916. Std of Reward: 0.7782425756702938.\n",
      "Step: 980000. Mean Reward: 0.1331836241690885. Std of Reward: 0.6889473040298056.\n",
      "Saved Model\n",
      "Step: 985000. Mean Reward: 0.07244156251298697. Std of Reward: 0.7442130088387028.\n",
      "Step: 990000. Mean Reward: 0.10558201515608465. Std of Reward: 0.7251537383698514.\n",
      "Step: 995000. Mean Reward: 0.0880657939486842. Std of Reward: 0.7305243780388914.\n",
      "Step: 1000000. Mean Reward: 0.06912304107591621. Std of Reward: 0.7535058676133742.\n",
      "Saved Model\n",
      "Step: 1005000. Mean Reward: 0.09409387671316814. Std of Reward: 0.7296843879176967.\n",
      "Step: 1010000. Mean Reward: 0.03030928258634017. Std of Reward: 0.7845459062205022.\n",
      "Step: 1015000. Mean Reward: 0.10332464641460232. Std of Reward: 0.7273654703834695.\n",
      "Step: 1020000. Mean Reward: 0.04607792642077919. Std of Reward: 0.7783138266936593.\n",
      "Saved Model\n",
      "Step: 1025000. Mean Reward: 0.05520888125326366. Std of Reward: 0.7653306244732138.\n",
      "Step: 1030000. Mean Reward: 0.042353710312093604. Std of Reward: 0.7726931289664275.\n",
      "Step: 1035000. Mean Reward: 0.02241466836536027. Std of Reward: 0.7955609223598249.\n",
      "Step: 1040000. Mean Reward: 0.04684210881077691. Std of Reward: 0.7784058032813342.\n",
      "Saved Model\n",
      "Step: 1045000. Mean Reward: 0.14944514890037827. Std of Reward: 0.7295165510188728.\n",
      "Step: 1050000. Mean Reward: 0.09211660702534852. Std of Reward: 0.7567989817270441.\n",
      "Step: 1055000. Mean Reward: 0.17859825178097619. Std of Reward: 0.7202075488109893.\n",
      "Step: 1060000. Mean Reward: 0.10083941938686129. Std of Reward: 0.7815543210132205.\n",
      "Saved Model\n",
      "Step: 1065000. Mean Reward: 0.16545679350123454. Std of Reward: 0.7475247076274303.\n",
      "Step: 1070000. Mean Reward: 0.1734375038822115. Std of Reward: 0.7372745503862698.\n",
      "Step: 1075000. Mean Reward: 0.16555160534519572. Std of Reward: 0.7420883778891265.\n",
      "Step: 1080000. Mean Reward: 0.20550996866119575. Std of Reward: 0.7348970984724136.\n",
      "Saved Model\n",
      "Step: 1085000. Mean Reward: 0.16326767410776358. Std of Reward: 0.7653298404493889.\n",
      "Step: 1090000. Mean Reward: 0.18630559069555297. Std of Reward: 0.7595376315438546.\n",
      "Step: 1095000. Mean Reward: 0.24235968272737685. Std of Reward: 0.7368241971097201.\n",
      "Step: 1100000. Mean Reward: 0.17470923938996577. Std of Reward: 0.7780265159307678.\n",
      "Saved Model\n",
      "Step: 1105000. Mean Reward: 0.2845091363458904. Std of Reward: 0.7050595768978324.\n",
      "Step: 1110000. Mean Reward: 0.2025481347701019. Std of Reward: 0.7618044740536158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1115000. Mean Reward: 0.2280518049898648. Std of Reward: 0.7598799179822355.\n",
      "Step: 1120000. Mean Reward: 0.26364666277463195. Std of Reward: 0.7165499155441966.\n",
      "Saved Model\n",
      "Step: 1125000. Mean Reward: 0.22696230927272723. Std of Reward: 0.7564780675375565.\n",
      "Step: 1130000. Mean Reward: 0.23501680090817467. Std of Reward: 0.7393383488218465.\n",
      "Step: 1135000. Mean Reward: 0.19450331440397348. Std of Reward: 0.7741112029601623.\n",
      "Step: 1140000. Mean Reward: 0.1876829301152993. Std of Reward: 0.775389508666257.\n",
      "Saved Model\n",
      "Step: 1145000. Mean Reward: 0.25618202358379577. Std of Reward: 0.7301010735880786.\n",
      "Step: 1150000. Mean Reward: 0.2106383014255319. Std of Reward: 0.746998276668698.\n",
      "Step: 1155000. Mean Reward: 0.24933185191648105. Std of Reward: 0.7430182835727646.\n",
      "Step: 1160000. Mean Reward: 0.27310690761692646. Std of Reward: 0.7276233031986318.\n",
      "Saved Model\n",
      "Step: 1165000. Mean Reward: 0.25835189679844095. Std of Reward: 0.7269833955855265.\n",
      "Step: 1170000. Mean Reward: 0.25867187862611607. Std of Reward: 0.7276979670625169.\n",
      "Step: 1175000. Mean Reward: 0.2471902687865044. Std of Reward: 0.7472692651840391.\n",
      "Step: 1180000. Mean Reward: 0.2733370571127232. Std of Reward: 0.7223122311670569.\n",
      "Saved Model\n",
      "Step: 1185000. Mean Reward: 0.22591814489269907. Std of Reward: 0.7630777510524116.\n",
      "Step: 1190000. Mean Reward: 0.20206858751769904. Std of Reward: 0.7627837012338893.\n",
      "Step: 1195000. Mean Reward: 0.2109748113001095. Std of Reward: 0.7732026353802645.\n",
      "Step: 1200000. Mean Reward: 0.2619052894405286. Std of Reward: 0.7462719421915339.\n",
      "Saved Model\n",
      "Step: 1205000. Mean Reward: 0.23854928371207085. Std of Reward: 0.7438055755293761.\n",
      "Step: 1210000. Mean Reward: 0.19775711454923411. Std of Reward: 0.7757971150334898.\n",
      "Step: 1215000. Mean Reward: 0.22687293161988947. Std of Reward: 0.7475612297103444.\n",
      "Step: 1220000. Mean Reward: 0.22533039974008806. Std of Reward: 0.7542953375079354.\n",
      "Saved Model\n",
      "Step: 1225000. Mean Reward: 0.1745504416589912. Std of Reward: 0.7804463531985434.\n",
      "Step: 1230000. Mean Reward: 0.2262793332815642. Std of Reward: 0.7327117397919733.\n",
      "Step: 1235000. Mean Reward: 0.22720088132601535. Std of Reward: 0.7547699496426605.\n",
      "Step: 1240000. Mean Reward: 0.20673558502829162. Std of Reward: 0.7749810683798174.\n",
      "Saved Model\n",
      "Step: 1245000. Mean Reward: 0.22951219863968958. Std of Reward: 0.7422088945096782.\n",
      "Step: 1250000. Mean Reward: 0.22880133541731404. Std of Reward: 0.744487180607781.\n",
      "Step: 1255000. Mean Reward: 0.23985619805309732. Std of Reward: 0.7400483441843095.\n",
      "Step: 1260000. Mean Reward: 0.2537130370963855. Std of Reward: 0.7595611187453974.\n",
      "Saved Model\n",
      "Step: 1265000. Mean Reward: 0.24181518484158412. Std of Reward: 0.7453156287177116.\n",
      "Step: 1270000. Mean Reward: 0.20744774793069304. Std of Reward: 0.7661475357641593.\n",
      "Step: 1275000. Mean Reward: 0.22166484426286964. Std of Reward: 0.7643729548152883.\n",
      "Step: 1280000. Mean Reward: 0.2166006632849285. Std of Reward: 0.7572701520472814.\n",
      "Saved Model\n",
      "Step: 1285000. Mean Reward: 0.2400111518940914. Std of Reward: 0.7333505380636037.\n",
      "Step: 1290000. Mean Reward: 0.26194505809780216. Std of Reward: 0.7435738310569359.\n",
      "Step: 1295000. Mean Reward: 0.23289011314725272. Std of Reward: 0.7518886845057281.\n",
      "Step: 1300000. Mean Reward: 0.23414634502328155. Std of Reward: 0.7406983387275458.\n",
      "Saved Model\n",
      "Step: 1305000. Mean Reward: 0.245354770575388. Std of Reward: 0.7391526264124915.\n",
      "Step: 1310000. Mean Reward: 0.2210840743274336. Std of Reward: 0.7461487692621901.\n",
      "Step: 1315000. Mean Reward: 0.24612832209402652. Std of Reward: 0.7380321317770899.\n",
      "Step: 1320000. Mean Reward: 0.2538199812788145. Std of Reward: 0.7438983468969281.\n",
      "Saved Model\n",
      "Step: 1325000. Mean Reward: 0.23207048788766518. Std of Reward: 0.749516664372168.\n",
      "Step: 1330000. Mean Reward: 0.1970032963798024. Std of Reward: 0.7639889831737638.\n",
      "Step: 1335000. Mean Reward: 0.26307863022923583. Std of Reward: 0.7265085445527532.\n",
      "Step: 1340000. Mean Reward: 0.24590414235185185. Std of Reward: 0.7590438033301187.\n",
      "Saved Model\n",
      "Step: 1345000. Mean Reward: 0.21348634172568304. Std of Reward: 0.7737009066110564.\n",
      "Step: 1350000. Mean Reward: 0.24645304211712704. Std of Reward: 0.7333283811279226.\n",
      "Step: 1355000. Mean Reward: 0.27292308027252743. Std of Reward: 0.7278085621279948.\n",
      "Step: 1360000. Mean Reward: 0.25629301124861265. Std of Reward: 0.7295477899002942.\n",
      "Saved Model\n",
      "Step: 1365000. Mean Reward: 0.2575328979451754. Std of Reward: 0.7422217641597029.\n",
      "Step: 1370000. Mean Reward: 0.2602564140033444. Std of Reward: 0.7260826631653554.\n",
      "Step: 1375000. Mean Reward: 0.22737074025082507. Std of Reward: 0.7549920533188422.\n",
      "Step: 1380000. Mean Reward: 0.27378705041273327. Std of Reward: 0.7455476594119359.\n",
      "Saved Model\n",
      "Step: 1385000. Mean Reward: 0.23671460513274334. Std of Reward: 0.74004958561706.\n",
      "Step: 1390000. Mean Reward: 0.2754203574502212. Std of Reward: 0.7216869997505424.\n",
      "Step: 1395000. Mean Reward: 0.293145075517165. Std of Reward: 0.7096481660033734.\n",
      "Step: 1400000. Mean Reward: 0.23040615017782654. Std of Reward: 0.7513536639749163.\n",
      "Saved Model\n",
      "Step: 1405000. Mean Reward: 0.22475517151468985. Std of Reward: 0.7683470956085897.\n",
      "Step: 1410000. Mean Reward: 0.28447745108910893. Std of Reward: 0.7236453357808944.\n",
      "Step: 1415000. Mean Reward: 0.24237885795264316. Std of Reward: 0.744060818134092.\n",
      "Step: 1420000. Mean Reward: 0.25351262663995605. Std of Reward: 0.7462616387732659.\n",
      "Saved Model\n",
      "Step: 1425000. Mean Reward: 0.20069155108671788. Std of Reward: 0.7617942494629306.\n",
      "Step: 1430000. Mean Reward: 0.2580000033824176. Std of Reward: 0.7385192798151993.\n",
      "Step: 1435000. Mean Reward: 0.19822368733552628. Std of Reward: 0.7709129100841228.\n",
      "Step: 1440000. Mean Reward: 0.27243392415748896. Std of Reward: 0.7288382541015737.\n",
      "Saved Model\n",
      "Step: 1445000. Mean Reward: 0.17889133138090005. Std of Reward: 0.7719112393972302.\n",
      "Step: 1450000. Mean Reward: 0.23717582745384613. Std of Reward: 0.7442199569816434.\n",
      "Step: 1455000. Mean Reward: 0.2524944846125828. Std of Reward: 0.7373724036090282.\n",
      "Step: 1460000. Mean Reward: 0.2732893322354235. Std of Reward: 0.7294782153412763.\n",
      "Saved Model\n",
      "Step: 1465000. Mean Reward: 0.23727869159781417. Std of Reward: 0.7550026419441859.\n",
      "Step: 1470000. Mean Reward: 0.2982268754900881. Std of Reward: 0.7192461533039994.\n",
      "Step: 1475000. Mean Reward: 0.1955104312294182. Std of Reward: 0.7630214214892711.\n",
      "Step: 1480000. Mean Reward: 0.22844617450610427. Std of Reward: 0.736011407958737.\n",
      "Saved Model\n",
      "Step: 1485000. Mean Reward: 0.23343921461664835. Std of Reward: 0.7504322246891533.\n",
      "Step: 1490000. Mean Reward: 0.23384113449727964. Std of Reward: 0.7688999406619373.\n",
      "Step: 1495000. Mean Reward: 0.2173932123636363. Std of Reward: 0.7596303919147541.\n",
      "Step: 1500000. Mean Reward: 0.2862527753048781. Std of Reward: 0.7095232273975851.\n",
      "Saved Model\n",
      "Step: 1505000. Mean Reward: 0.2207692340263736. Std of Reward: 0.755330553481262.\n",
      "Step: 1510000. Mean Reward: 0.2617343610812294. Std of Reward: 0.7415600940582315.\n",
      "Step: 1515000. Mean Reward: 0.25867033286483515. Std of Reward: 0.7411174310496842.\n",
      "Step: 1520000. Mean Reward: 0.22317180951541848. Std of Reward: 0.7475997323920012.\n",
      "Saved Model\n",
      "Step: 1525000. Mean Reward: 0.21038504180638062. Std of Reward: 0.7529939996965308.\n",
      "Step: 1530000. Mean Reward: 0.23356589504983385. Std of Reward: 0.737748452314101.\n",
      "Step: 1535000. Mean Reward: 0.22782037558269436. Std of Reward: 0.7550037275573287.\n",
      "Step: 1540000. Mean Reward: 0.24103638707607494. Std of Reward: 0.742061869536837.\n",
      "Saved Model\n",
      "Step: 1545000. Mean Reward: 0.25621413139072846. Std of Reward: 0.7342700086830087.\n",
      "Step: 1550000. Mean Reward: 0.2871208825032967. Std of Reward: 0.7243026640218008.\n",
      "Step: 1555000. Mean Reward: 0.20832967371208788. Std of Reward: 0.7551544945124512.\n",
      "Step: 1560000. Mean Reward: 0.24006572059912373. Std of Reward: 0.748600591046166.\n",
      "Saved Model\n",
      "Step: 1565000. Mean Reward: 0.24344713991189426. Std of Reward: 0.7373046757220696.\n",
      "Step: 1570000. Mean Reward: 0.2655260279401993. Std of Reward: 0.7216211035515311.\n",
      "Step: 1575000. Mean Reward: 0.2577521961282895. Std of Reward: 0.7442668985277487.\n",
      "Step: 1580000. Mean Reward: 0.25537527944039734. Std of Reward: 0.7298009373529063.\n",
      "Saved Model\n",
      "Step: 1585000. Mean Reward: 0.2348783221360619. Std of Reward: 0.7367359459954642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1590000. Mean Reward: 0.2575438629824561. Std of Reward: 0.7396384396204653.\n",
      "Step: 1595000. Mean Reward: 0.2317301443939064. Std of Reward: 0.7646793053549111.\n",
      "Step: 1600000. Mean Reward: 0.23165555910222219. Std of Reward: 0.7371840074213141.\n",
      "Saved Model\n",
      "Step: 1605000. Mean Reward: 0.2278022011010989. Std of Reward: 0.7483141535151524.\n",
      "Step: 1610000. Mean Reward: 0.22680874624262296. Std of Reward: 0.7592163654071304.\n",
      "Step: 1615000. Mean Reward: 0.31114664061742003. Std of Reward: 0.7061409704039359.\n",
      "Step: 1620000. Mean Reward: 0.22852459323715846. Std of Reward: 0.7574396833272931.\n",
      "Saved Model\n",
      "Step: 1625000. Mean Reward: 0.20940217692826085. Std of Reward: 0.7705654139615732.\n",
      "Step: 1630000. Mean Reward: 0.23581678050220747. Std of Reward: 0.7457779964607193.\n",
      "Step: 1635000. Mean Reward: 0.26067982779057014. Std of Reward: 0.740932896227588.\n",
      "Step: 1640000. Mean Reward: 0.2322342761008676. Std of Reward: 0.7699794336123174.\n",
      "Saved Model\n",
      "Step: 1645000. Mean Reward: 0.2482249206196251. Std of Reward: 0.7397979726037567.\n",
      "Step: 1650000. Mean Reward: 0.224492914610687. Std of Reward: 0.7659101901429725.\n",
      "Step: 1655000. Mean Reward: 0.23878721399889744. Std of Reward: 0.7444443754450493.\n",
      "Step: 1660000. Mean Reward: 0.2355653161800219. Std of Reward: 0.750370186909326.\n",
      "Saved Model\n",
      "Step: 1665000. Mean Reward: 0.285570324854928. Std of Reward: 0.7120115487868119.\n",
      "Step: 1670000. Mean Reward: 0.2395359150872928. Std of Reward: 0.7334327120408393.\n",
      "Step: 1675000. Mean Reward: 0.24940528969162992. Std of Reward: 0.7429568561359002.\n",
      "Step: 1680000. Mean Reward: 0.2645683090633879. Std of Reward: 0.7452962924267545.\n",
      "Saved Model\n",
      "Step: 1685000. Mean Reward: 0.2758817118992333. Std of Reward: 0.7303658675923075.\n",
      "Step: 1690000. Mean Reward: 0.21495595048458147. Std of Reward: 0.7511007339564999.\n",
      "Step: 1695000. Mean Reward: 0.23734671505128205. Std of Reward: 0.7230860152424495.\n",
      "Step: 1700000. Mean Reward: 0.2722925794061135. Std of Reward: 0.7498615494781847.\n",
      "Saved Model\n",
      "Step: 1705000. Mean Reward: 0.23918033108743167. Std of Reward: 0.7562141010572211.\n",
      "Step: 1710000. Mean Reward: 0.250285403870472. Std of Reward: 0.7452044467480018.\n",
      "Step: 1715000. Mean Reward: 0.1789479548504983. Std of Reward: 0.7545888427912625.\n",
      "Step: 1720000. Mean Reward: 0.1883206138364231. Std of Reward: 0.7745599343702492.\n",
      "Saved Model\n",
      "Step: 1725000. Mean Reward: 0.25541436812596685. Std of Reward: 0.7304590783811982.\n",
      "Step: 1730000. Mean Reward: 0.24328918666225163. Std of Reward: 0.7380934208859165.\n",
      "Step: 1735000. Mean Reward: 0.2617030597969432. Std of Reward: 0.7512699178777403.\n",
      "Step: 1740000. Mean Reward: 0.24214597245860567. Std of Reward: 0.7610569660241789.\n",
      "Saved Model\n",
      "Step: 1745000. Mean Reward: 0.25274033497679554. Std of Reward: 0.7321627731794992.\n",
      "Step: 1750000. Mean Reward: 0.23458605970806096. Std of Reward: 0.7656741187366966.\n",
      "Step: 1755000. Mean Reward: 0.24674317249289615. Std of Reward: 0.7479705847109208.\n",
      "Step: 1760000. Mean Reward: 0.2704385997203947. Std of Reward: 0.736038788670341.\n",
      "Saved Model\n",
      "Step: 1765000. Mean Reward: 0.256480877493989. Std of Reward: 0.7468800457096414.\n",
      "Step: 1770000. Mean Reward: 0.23375824503626372. Std of Reward: 0.7502030114853565.\n",
      "Step: 1775000. Mean Reward: 0.2332420624129244. Std of Reward: 0.7546309782274164.\n",
      "Step: 1780000. Mean Reward: 0.24792222593777777. Std of Reward: 0.7230706251684714.\n",
      "Saved Model\n",
      "Step: 1785000. Mean Reward: 0.2514364067796052. Std of Reward: 0.7432898801955625.\n",
      "Step: 1790000. Mean Reward: 0.2701762148645374. Std of Reward: 0.7326738588486652.\n",
      "Step: 1795000. Mean Reward: 0.24630820752993343. Std of Reward: 0.7313957192875934.\n",
      "Step: 1800000. Mean Reward: 0.27895604725494505. Std of Reward: 0.7293204043067948.\n",
      "Saved Model\n",
      "Step: 1805000. Mean Reward: 0.20582154809357997. Std of Reward: 0.7748481939823625.\n",
      "Step: 1810000. Mean Reward: 0.19469231084505492. Std of Reward: 0.7663761345150357.\n",
      "Step: 1815000. Mean Reward: 0.26168701811875694. Std of Reward: 0.719556865963625.\n",
      "Step: 1820000. Mean Reward: 0.20794279747744773. Std of Reward: 0.7573213278846136.\n",
      "Saved Model\n",
      "Step: 1825000. Mean Reward: 0.26810781406270623. Std of Reward: 0.731311905504619.\n",
      "Step: 1830000. Mean Reward: 0.2385651249779249. Std of Reward: 0.73735007910778.\n",
      "Step: 1835000. Mean Reward: 0.24647640283534575. Std of Reward: 0.7459406356988895.\n",
      "Step: 1840000. Mean Reward: 0.26528115000992275. Std of Reward: 0.7346216875244238.\n",
      "Saved Model\n",
      "Step: 1845000. Mean Reward: 0.27377338070297025. Std of Reward: 0.7314624788733792.\n",
      "Step: 1850000. Mean Reward: 0.2612651298151815. Std of Reward: 0.7340640271954432.\n",
      "Step: 1855000. Mean Reward: 0.21428415618251365. Std of Reward: 0.7589499559234079.\n",
      "Step: 1860000. Mean Reward: 0.2081947514978118. Std of Reward: 0.7614268268630332.\n",
      "Saved Model\n",
      "Step: 1865000. Mean Reward: 0.23586696057797163. Std of Reward: 0.7568898631120928.\n",
      "Step: 1870000. Mean Reward: 0.2194573680232558. Std of Reward: 0.741114986916903.\n",
      "Step: 1875000. Mean Reward: 0.22235359462430937. Std of Reward: 0.7446885131783125.\n",
      "Step: 1880000. Mean Reward: 0.24173245949451752. Std of Reward: 0.7484827224914273.\n",
      "Saved Model\n",
      "Step: 1885000. Mean Reward: 0.21041942950883. Std of Reward: 0.7484873946791403.\n",
      "Step: 1890000. Mean Reward: 0.19119256337636759. Std of Reward: 0.7700152046181132.\n",
      "Step: 1895000. Mean Reward: 0.23971334407717745. Std of Reward: 0.7377362846470192.\n",
      "Step: 1900000. Mean Reward: 0.24463415006984476. Std of Reward: 0.7274101545187934.\n",
      "Saved Model\n",
      "Step: 1905000. Mean Reward: 0.23578022307912086. Std of Reward: 0.7474511982808987.\n",
      "Step: 1910000. Mean Reward: 0.21106476741602634. Std of Reward: 0.7527810630603502.\n",
      "Step: 1915000. Mean Reward: 0.27585339476148796. Std of Reward: 0.739925321085785.\n",
      "Step: 1920000. Mean Reward: 0.25864388431973534. Std of Reward: 0.7326978385332361.\n",
      "Saved Model\n",
      "Step: 1925000. Mean Reward: 0.19859956546061266. Std of Reward: 0.7694349919348479.\n",
      "Step: 1930000. Mean Reward: 0.2168954277135076. Std of Reward: 0.7686538988658412.\n",
      "Step: 1935000. Mean Reward: 0.22587336568122268. Std of Reward: 0.7605173792089643.\n",
      "Step: 1940000. Mean Reward: 0.20581243486804793. Std of Reward: 0.7705674389313295.\n",
      "Saved Model\n",
      "Step: 1945000. Mean Reward: 0.27746401245736435. Std of Reward: 0.7155415157862268.\n",
      "Step: 1950000. Mean Reward: 0.19742391609999999. Std of Reward: 0.773725878414426.\n",
      "Step: 1955000. Mean Reward: 0.2603307642271223. Std of Reward: 0.7335339104785027.\n",
      "Step: 1960000. Mean Reward: 0.22941436804198892. Std of Reward: 0.7456395461407016.\n",
      "Saved Model\n",
      "Step: 1965000. Mean Reward: 0.24081229743578483. Std of Reward: 0.7440632212151762.\n",
      "Step: 1970000. Mean Reward: 0.23330377300332591. Std of Reward: 0.7356070214015283.\n",
      "Step: 1975000. Mean Reward: 0.25317234151042806. Std of Reward: 0.7362994764457319.\n",
      "Step: 1980000. Mean Reward: 0.21718853712568909. Std of Reward: 0.743937594667259.\n",
      "Saved Model\n",
      "Step: 1985000. Mean Reward: 0.25263676487636755. Std of Reward: 0.7463864417726205.\n",
      "Step: 1990000. Mean Reward: 0.25646409181988944. Std of Reward: 0.7357828817906465.\n",
      "Step: 1995000. Mean Reward: 0.21809989447557. Std of Reward: 0.7683339112135644.\n",
      "Step: 2000000. Mean Reward: 0.25150776421840354. Std of Reward: 0.7254929899841116.\n",
      "Saved Model\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons16/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons16/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 7 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 7 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons16/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/scifibuttons16/model-2000001.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 7 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 7 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
